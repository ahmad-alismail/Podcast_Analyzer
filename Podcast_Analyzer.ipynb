{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Kabanosk/whisper-website\n",
    "https://github.com/openai/whisper/discussions/264"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yt_dlp\n",
    "import unzip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Audio and Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_URL = \"https://youtu.be/DgTjSrrf6GQ\"\n",
    "AUDIO_FILE_NAME = \"./data/Lex_Podcast.mp3\"\n",
    "AUDIO_QUALITY = 5 # 0 best - 10 worst (default 5)\n",
    "AUDIO_FORMAT = \"mp3\"\n",
    "FFMPEG_LOCATION = \"ffmpeg-master-latest-win64-gpl/bin\"\n",
    "SUBTITLE_LANGUAGE = \"en.*\"\n",
    "TRANSCRIPT_FILE_NAME = \"./data/transcript.txt\"\n",
    "SUBTITLE_FORMAT = \"srt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ffmpeg...\n",
      "Unzipping...\n",
      "Removing zip file...\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "FFMPEG_URL = 'https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-win64-gpl.zip'\n",
    "ZIP_PATH = './ffmpeg.zip'\n",
    "EXTRACT_DIR = './'\n",
    "\n",
    "if not os.path.exists(ZIP_PATH):\n",
    "    print('Downloading ffmpeg...')\n",
    "    wget.download(FFMPEG_URL, ZIP_PATH)\n",
    "\n",
    "    print('Unzipping...') \n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    \n",
    "    print('Removing zip file...')\n",
    "    os.remove(ZIP_PATH)\n",
    "\n",
    "else:\n",
    "    print('Already downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yt-dlp -xv --ffmpeg-location ffmpeg-master-latest-win64-gpl/bin --audio-format mp3  -o data/Lex_Podcast -- {\"https://youtu.be/DEu24V8vfb8\"}\n",
    "#!yt-dlp -xv --ffmpeg-location {FFMPEG_LOCATION} --audio-format {AUDIO_FORMAT}  -o {AUDIO_FILE_NAME} -- {\"https://youtu.be/DEu24V8vfb8\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "audio_file = open(\"audio.mp3\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, response_format=SUBTITLE_FORMAT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longer Inputs\n",
    "By default, the Whisper API only supports files that are less than 25 MB. If you have an audio file that is longer than that, you will need to break it up into chunks of 25 MB's or less or used a compressed audio format. To get the best performance, we suggest that you avoid breaking the audio up mid-sentence as this may cause some context to be lost.\n",
    "\n",
    "One way to handle this is to use the [PyDub open source Python package](https://github.com/jiaaro/pydub) to split the audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "song = AudioSegment.from_mp3(\"good_morning.mp3\")\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "ten_minutes = 10 * 60 * 1000\n",
    "\n",
    "first_10_minutes = song[:ten_minutes]\n",
    "\n",
    "first_10_minutes.export(\"good_morning_10.mp3\", format=\"mp3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting\n",
    "* Check out [OpenAI](https://platform.openai.com/docs/guides/speech-to-text/prompting)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://youtu.be/DgTjSrrf6GQ\n",
      "[youtube] DgTjSrrf6GQ: Downloading webpage\n",
      "[youtube] DgTjSrrf6GQ: Downloading android player API JSON\n",
      "[info] DgTjSrrf6GQ: Downloading subtitles: en-orig, en, en-en-ehkg1hFWq8A\n",
      "[info] DgTjSrrf6GQ: Downloading 1 format(s): 22\n",
      "[info] Writing video subtitles to: transcript.txt.en-orig.vtt\n",
      "[download] Destination: transcript.txt.en-orig.vtt\n",
      "\n",
      "[download]    1.00KiB at  909.63KiB/s (00:00:00)\n",
      "[download]    3.00KiB at    1.45MiB/s (00:00:00)\n",
      "[download]    7.00KiB at    1.32MiB/s (00:00:00)\n",
      "[download]   15.00KiB at    1.17MiB/s (00:00:00)\n",
      "[download]   31.00KiB at  729.35KiB/s (00:00:00)\n",
      "[download]   63.00KiB at  978.15KiB/s (00:00:00)\n",
      "[download]  127.00KiB at    1.33MiB/s (00:00:00)\n",
      "[download]  255.00KiB at    2.07MiB/s (00:00:00)\n",
      "[download]  511.00KiB at    3.35MiB/s (00:00:00)\n",
      "[download]  816.60KiB at    4.29MiB/s (00:00:00)\n",
      "[download] 100% of  816.60KiB in 00:00:00 at 1.88MiB/s\n",
      "[info] Writing video subtitles to: transcript.txt.en.vtt\n",
      "[download] Destination: transcript.txt.en.vtt\n",
      "\n",
      "[download]    1.00KiB at  965.54KiB/s (00:00:00)\n",
      "[download]    3.00KiB at    1.47MiB/s (00:00:00)\n",
      "[download]    7.00KiB at    2.28MiB/s (00:00:00)\n",
      "[download]   15.00KiB at    1.48MiB/s (00:00:00)\n",
      "[download]   31.00KiB at  917.91KiB/s (00:00:00)\n",
      "[download]   63.00KiB at    1.05MiB/s (00:00:00)\n",
      "[download]  127.00KiB at    1.50MiB/s (00:00:00)\n",
      "[download]  255.00KiB at    2.26MiB/s (00:00:00)\n",
      "[download]  511.00KiB at    3.53MiB/s (00:00:00)\n",
      "[download]  816.60KiB at    4.41MiB/s (00:00:00)\n",
      "[download] 100% of  816.60KiB in 00:00:00 at 2.06MiB/s\n",
      "[info] Writing video subtitles to: transcript.txt.en-en-ehkg1hFWq8A.vtt\n",
      "[download] Destination: transcript.txt.en-en-ehkg1hFWq8A.vtt\n",
      "\n",
      "[download]    1.00KiB at  906.88KiB/s (00:00:00)\n",
      "[download]    3.00KiB at    2.66MiB/s (00:00:00)\n",
      "[download]    7.00KiB at    2.03MiB/s (00:00:00)\n",
      "[download]   15.00KiB at    1.34MiB/s (00:00:00)\n",
      "[download]   31.00KiB at  704.03KiB/s (00:00:00)\n",
      "[download]   63.00KiB at  921.55KiB/s (00:00:00)\n",
      "[download]  127.00KiB at    1.28MiB/s (00:00:00)\n",
      "[download]  150.19KiB at    1.42MiB/s (00:00:00)\n",
      "[download] 100% of  150.19KiB in 00:00:00 at 579.33KiB/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: No subtitle format found matching \"srt\" for language en-orig, using vtt\n",
      "WARNING: No subtitle format found matching \"srt\" for language en, using vtt\n",
      "WARNING: No subtitle format found matching \"srt\" for language en-en-ehkg1hFWq8A, using vtt\n"
     ]
    }
   ],
   "source": [
    "# Download the transcript with yt-dlp\n",
    "!yt-dlp --write-auto-sub --skip-download --sub-format {SUBTITLE_FORMAT} --sub-lang {SUBTITLE_LANGUAGE} --output {TRANSCRIPT_FILE_NAME} -- {VIDEO_URL}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's change the name of the raw caption files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a clean list of podcast titles\n",
    "import re \n",
    "\n",
    "def clean_titles(title):\n",
    "    # Remove web links\n",
    "    title = re.sub(r'\\[(.*?)\\]\\((.*?)\\)', r'\\1', title)\n",
    "    # Remove the pattern | Lex Fridman Podcast #1 \n",
    "    title = re.sub(r'\\|.*?\\d+', '', title)\n",
    "    title = title.rstrip().replace(' ', '_').replace(':', '_').replace('&','and').lower()\n",
    "    #.replace(',', '').replace('&','')\n",
    "    # remove special characters\n",
    "    title = re.sub(r'[^a-zA-Z0-9_]', '', title)\n",
    "    return title\n",
    "\n",
    "with open('./data/Lexicap.md', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "titles = text.split('\\n')\n",
    "\n",
    "titles = [clean_titles(title) for title in titles if title != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1_max_tegmark__life_30'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode_001_large.vtt\n",
      "episode_002_large.vtt\n",
      "episode_003_large.vtt\n",
      "episode_004_large.vtt\n",
      "episode_005_large.vtt\n",
      "episode_006_large.vtt\n",
      "episode_007_large.vtt\n",
      "episode_008_large.vtt\n",
      "episode_009_large.vtt\n",
      "episode_010_large.vtt\n",
      "episode_011_large.vtt\n",
      "episode_012_large.vtt\n",
      "episode_013_large.vtt\n",
      "episode_014_large.vtt\n",
      "episode_015_large.vtt\n",
      "episode_016_large.vtt\n",
      "episode_017_large.vtt\n",
      "episode_018_large.vtt\n",
      "episode_019_large.vtt\n",
      "episode_020_large.vtt\n",
      "episode_021_large.vtt\n",
      "episode_022_large.vtt\n",
      "episode_023_large.vtt\n",
      "episode_024_large.vtt\n",
      "episode_025_large.vtt\n",
      "episode_026_large.vtt\n",
      "episode_027_large.vtt\n",
      "episode_028_large.vtt\n",
      "episode_029_large.vtt\n",
      "episode_030_large.vtt\n",
      "episode_031_large.vtt\n",
      "episode_032_large.vtt\n",
      "episode_033_large.vtt\n",
      "episode_034_large.vtt\n",
      "episode_035_large.vtt\n",
      "episode_036_large.vtt\n",
      "episode_037_large.vtt\n",
      "episode_038_large.vtt\n",
      "episode_039_large.vtt\n",
      "episode_040_large.vtt\n",
      "episode_041_large.vtt\n",
      "episode_042_large.vtt\n",
      "episode_043_large.vtt\n",
      "episode_044_large.vtt\n",
      "episode_045_large.vtt\n",
      "episode_046_large.vtt\n",
      "episode_047_large.vtt\n",
      "episode_048_large.vtt\n",
      "episode_049_large.vtt\n",
      "episode_050_large.vtt\n",
      "episode_051_large.vtt\n",
      "episode_052_large.vtt\n",
      "episode_053_large.vtt\n",
      "episode_054_large.vtt\n",
      "episode_055_large.vtt\n",
      "episode_056_large.vtt\n",
      "episode_057_large.vtt\n",
      "episode_058_large.vtt\n",
      "episode_059_large.vtt\n",
      "episode_060_large.vtt\n",
      "episode_061_large.vtt\n",
      "episode_062_large.vtt\n",
      "episode_063_large.vtt\n",
      "episode_064_large.vtt\n",
      "episode_065_large.vtt\n",
      "episode_066_large.vtt\n",
      "episode_067_large.vtt\n",
      "episode_068_large.vtt\n",
      "episode_069_large.vtt\n",
      "episode_070_large.vtt\n",
      "episode_071_large.vtt\n",
      "episode_072_large.vtt\n",
      "episode_073_large.vtt\n",
      "episode_074_large.vtt\n",
      "episode_075_large.vtt\n",
      "episode_076_large.vtt\n",
      "episode_077_large.vtt\n",
      "episode_078_large.vtt\n",
      "episode_079_large.vtt\n",
      "episode_080_large.vtt\n",
      "episode_081_large.vtt\n",
      "episode_082_large.vtt\n",
      "episode_083_large.vtt\n",
      "episode_084_large.vtt\n",
      "episode_085_large.vtt\n",
      "episode_086_large.vtt\n",
      "episode_087_large.vtt\n",
      "episode_088_large.vtt\n",
      "episode_089_large.vtt\n",
      "episode_090_large.vtt\n",
      "episode_091_large.vtt\n",
      "episode_092_large.vtt\n",
      "episode_093_large.vtt\n",
      "episode_094_large.vtt\n",
      "episode_095_large.vtt\n",
      "episode_096_large.vtt\n",
      "episode_097_large.vtt\n",
      "episode_098_large.vtt\n",
      "episode_099_large.vtt\n",
      "episode_101_large.vtt\n",
      "episode_102_large.vtt\n",
      "episode_103_large.vtt\n",
      "episode_104_large.vtt\n",
      "episode_105_large.vtt\n",
      "episode_106_large.vtt\n",
      "episode_107_large.vtt\n",
      "episode_108_large.vtt\n",
      "episode_109_large.vtt\n",
      "episode_110_large.vtt\n",
      "episode_111_large.vtt\n",
      "episode_112_large.vtt\n",
      "episode_113_large.vtt\n",
      "episode_114_large.vtt\n",
      "episode_115_large.vtt\n",
      "episode_116_large.vtt\n",
      "episode_117_large.vtt\n",
      "episode_118_large.vtt\n",
      "episode_119_large.vtt\n",
      "episode_120_large.vtt\n",
      "episode_121_large.vtt\n",
      "episode_122_large.vtt\n",
      "episode_123_large.vtt\n",
      "episode_124_large.vtt\n",
      "episode_125_large.vtt\n",
      "episode_126_large.vtt\n",
      "episode_127_large.vtt\n",
      "episode_128_large.vtt\n",
      "episode_129_large.vtt\n",
      "episode_130_large.vtt\n",
      "episode_131_large.vtt\n",
      "episode_132_large.vtt\n",
      "episode_133_large.vtt\n",
      "episode_134_large.vtt\n",
      "episode_135_large.vtt\n",
      "episode_136_large.vtt\n",
      "episode_137_large.vtt\n",
      "episode_138_large.vtt\n",
      "episode_139_large.vtt\n",
      "episode_140_large.vtt\n",
      "episode_141_large.vtt\n",
      "episode_142_large.vtt\n",
      "episode_143_large.vtt\n",
      "episode_144_large.vtt\n",
      "episode_145_large.vtt\n",
      "episode_146_large.vtt\n",
      "episode_147_large.vtt\n",
      "episode_148_large.vtt\n",
      "episode_149_large.vtt\n",
      "episode_150_large.vtt\n",
      "episode_151_large.vtt\n",
      "episode_152_large.vtt\n",
      "episode_153_large.vtt\n",
      "episode_154_large.vtt\n",
      "episode_155_large.vtt\n",
      "episode_156_large.vtt\n",
      "episode_157_large.vtt\n",
      "episode_158_large.vtt\n",
      "episode_159_large.vtt\n",
      "episode_160_large.vtt\n",
      "episode_161_large.vtt\n",
      "episode_162_large.vtt\n",
      "episode_163_large.vtt\n",
      "episode_164_large.vtt\n",
      "episode_165_large.vtt\n",
      "episode_166_large.vtt\n",
      "episode_167_large.vtt\n",
      "episode_168_large.vtt\n",
      "episode_169_large.vtt\n",
      "episode_170_large.vtt\n",
      "episode_171_large.vtt\n",
      "episode_172_large.vtt\n",
      "episode_173_large.vtt\n",
      "episode_174_large.vtt\n",
      "episode_175_large.vtt\n",
      "episode_176_large.vtt\n",
      "episode_177_large.vtt\n",
      "episode_178_large.vtt\n",
      "episode_179_large.vtt\n",
      "episode_180_large.vtt\n",
      "episode_181_large.vtt\n",
      "episode_182_large.vtt\n",
      "episode_183_large.vtt\n",
      "episode_184_large.vtt\n",
      "episode_185_large.vtt\n",
      "episode_186_large.vtt\n",
      "episode_187_large.vtt\n",
      "episode_188_large.vtt\n",
      "episode_189_large.vtt\n",
      "episode_190_large.vtt\n",
      "episode_191_large.vtt\n",
      "episode_192_large.vtt\n",
      "episode_193_large.vtt\n",
      "episode_194_large.vtt\n",
      "episode_195_large.vtt\n",
      "episode_196_large.vtt\n",
      "episode_197_large.vtt\n",
      "episode_198_large.vtt\n",
      "episode_199_large.vtt\n",
      "episode_200_large.vtt\n",
      "episode_201_large.vtt\n",
      "episode_202_large.vtt\n",
      "episode_203_large.vtt\n",
      "episode_204_large.vtt\n",
      "episode_205_large.vtt\n",
      "episode_206_large.vtt\n",
      "episode_207_large.vtt\n",
      "episode_208_large.vtt\n",
      "episode_209_large.vtt\n",
      "episode_210_large.vtt\n",
      "episode_211_large.vtt\n",
      "episode_212_large.vtt\n",
      "episode_213_large.vtt\n",
      "episode_214_large.vtt\n",
      "episode_215_large.vtt\n",
      "episode_216_large.vtt\n",
      "episode_217_large.vtt\n",
      "episode_218_large.vtt\n",
      "episode_219_large.vtt\n",
      "episode_220_large.vtt\n",
      "episode_221_large.vtt\n",
      "episode_222_large.vtt\n",
      "episode_223_large.vtt\n",
      "episode_224_large.vtt\n",
      "episode_225_large.vtt\n",
      "episode_226_large.vtt\n",
      "episode_227_large.vtt\n",
      "episode_228_large.vtt\n",
      "episode_229_large.vtt\n",
      "episode_230_large.vtt\n",
      "episode_231_large.vtt\n",
      "episode_232_large.vtt\n",
      "episode_233_large.vtt\n",
      "episode_234_large.vtt\n",
      "episode_235_large.vtt\n",
      "episode_236_large.vtt\n",
      "episode_237_large.vtt\n",
      "episode_238_large.vtt\n",
      "episode_239_large.vtt\n",
      "episode_240_large.vtt\n",
      "episode_241_large.vtt\n",
      "episode_242_large.vtt\n",
      "episode_243_large.vtt\n",
      "episode_244_large.vtt\n",
      "episode_245_large.vtt\n",
      "episode_246_large.vtt\n",
      "episode_247_large.vtt\n",
      "episode_248_large.vtt\n",
      "episode_249_large.vtt\n",
      "episode_250_large.vtt\n",
      "episode_251_large.vtt\n",
      "episode_252_large.vtt\n",
      "episode_253_large.vtt\n",
      "episode_254_large.vtt\n",
      "episode_255_large.vtt\n",
      "episode_256_large.vtt\n",
      "episode_257_large.vtt\n",
      "episode_258_large.vtt\n",
      "episode_259_large.vtt\n",
      "episode_260_large.vtt\n",
      "episode_261_large.vtt\n",
      "episode_262_large.vtt\n",
      "episode_263_large.vtt\n",
      "episode_264_large.vtt\n",
      "episode_265_large.vtt\n",
      "episode_266_large.vtt\n",
      "episode_267_large.vtt\n",
      "episode_269_large.vtt\n",
      "episode_270_large.vtt\n",
      "episode_271_large.vtt\n",
      "episode_272_large.vtt\n",
      "episode_273_large.vtt\n",
      "episode_274_large.vtt\n",
      "episode_275_large.vtt\n",
      "episode_276_large.vtt\n",
      "episode_277_large.vtt\n",
      "episode_278_large.vtt\n",
      "episode_279_large.vtt\n",
      "episode_280_large.vtt\n",
      "episode_281_large.vtt\n",
      "episode_284_large.vtt\n",
      "episode_285_large.vtt\n",
      "episode_286_large.vtt\n",
      "episode_288_large.vtt\n",
      "episode_289_large.vtt\n",
      "episode_290_large.vtt\n",
      "episode_292_large.vtt\n",
      "episode_293_large.vtt\n",
      "episode_294_large.vtt\n",
      "episode_295_large.vtt\n",
      "episode_296_large.vtt\n",
      "episode_297_large.vtt\n",
      "episode_298_large.vtt\n",
      "episode_299_large.vtt\n",
      "episode_300_large.vtt\n",
      "episode_301_large.vtt\n",
      "episode_302_large.vtt\n",
      "episode_303_large.vtt\n",
      "episode_304_large.vtt\n",
      "episode_305_large.vtt\n",
      "episode_306_large.vtt\n",
      "episode_307_large.vtt\n",
      "episode_308_large.vtt\n",
      "episode_309_large.vtt\n",
      "episode_310_large.vtt\n",
      "episode_311_large.vtt\n",
      "episode_312_large.vtt\n",
      "episode_313_large.vtt\n",
      "episode_314_large.vtt\n",
      "episode_315_large.vtt\n",
      "episode_316_large.vtt\n",
      "episode_317_large.vtt\n",
      "episode_318_large.vtt\n",
      "episode_319_large.vtt\n",
      "episode_320_large.vtt\n",
      "episode_321_large.vtt\n",
      "episode_322_large.vtt\n",
      "episode_323_large.vtt\n",
      "episode_324_large.vtt\n",
      "episode_325_large.vtt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "TRANSCRIPT_PATH = \"./data/transcripts/\"\n",
    "FILE_EXTENSION = '.vtt'\n",
    "\n",
    "for orig_filename, title in zip(os.listdir(path=TRANSCRIPT_PATH), titles):\n",
    "    if orig_filename.endswith(FILE_EXTENSION):\n",
    "        print(orig_filename)\n",
    "        # rename file \n",
    "        new_filename = f\"{title}{FILE_EXTENSION}\"\n",
    "        os.rename(f\"{TRANSCRIPT_PATH}{orig_filename}\", f\"{TRANSCRIPT_PATH}{new_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('./data/transcripts/Lexicap.md') as oldfile, open('newfile.txt', 'w') as newfile:\n",
    "    for title in oldfile:\n",
    "        # Remove web links and leave episode number\n",
    "        title = re.sub(r'\\[(.*?)\\]\\((.*?)\\)', r'\\1', title)\n",
    "        # Remove the pattern | Lex Fridman Podcast #1 \n",
    "        title = re.sub(r'\\|.*?\\d+', '', title)\n",
    "\n",
    "        newfile.write(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[debug] Command-line config: ['-v']\n",
      "[debug] Encodings: locale cp1252, fs utf-8, pref cp1252, out utf-8 (No ANSI), error utf-8 (No ANSI), screen utf-8 (No ANSI)\n",
      "[debug] yt-dlp version stable@2023.03.04 [392389b7d] (pip)\n",
      "[debug] Python 3.10.5 (CPython AMD64 64bit) - Windows-10-10.0.19044-SP0 (OpenSSL 1.1.1n  15 Mar 2022)\n",
      "[debug] exe versions: none\n",
      "[debug] Optional libraries: Cryptodome-3.18.0, brotli-1.0.9, certifi-2023.05.07, mutagen-1.46.0, sqlite3-2.6.0, websockets-11.0.3\n",
      "[debug] Proxy map: {}\n",
      "[debug] Loaded 1786 extractors\n",
      "\n",
      "Usage: yt-dlp [OPTIONS] URL [URL...]\n",
      "\n",
      "yt-dlp: error: You must provide at least one URL.\n",
      "Type yt-dlp --help to see a list of all options.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "bad_words = ['-->','</c>'] \n",
    "\n",
    "\n",
    "with open('example.en.vtt') as oldfile, open('newfile.txt', 'w') as newfile:\n",
    "    for title in oldfile:\n",
    "        if not any(bad_word in title for bad_word in bad_words):\n",
    "            newfile.write(title)\n",
    "\n",
    "\n",
    "with open('newfile.txt') as result:\n",
    "    uniqlines = set(result.readlines())\n",
    "    with open('sub_out.txt', 'w') as rmdup:\n",
    "        mylst = map(lambda each: each.strip(\"&gt;&gt;\"), uniqlines)\n",
    "        print(mylst)\n",
    "        rmdup.writelines(set(mylst))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "# Summarization of main topics in the audio\n",
    "# Go to the mentions of the topics\n",
    "# translation to arabic\n",
    "# The app ask me questions about the text (for language learning) and create a discussion\n",
    "# Overall sentiment in the text\n",
    "# Webapp or Mobile app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
