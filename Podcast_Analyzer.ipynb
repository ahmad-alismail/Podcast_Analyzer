{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yt_dlp\n",
    "import unzip\n",
    "from typing import List, Callable, Optional, Dict\n",
    "\n",
    "# increase column width\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Audio and Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_URL = \"https://youtu.be/DgTjSrrf6GQ\"\n",
    "AUDIO_FILE_NAME = \"./data/audio/Lex_Podcast.mp3\"\n",
    "AUDIO_QUALITY = 5 # 0 best - 10 worst (default 5)\n",
    "AUDIO_FORMAT = \"mp3\"\n",
    "FFMPEG_LOCATION = \"ffmpeg-master-latest-win64-gpl/bin\"\n",
    "SUBTITLE_LANGUAGE = \"en.*\"\n",
    "TRANSCRIPT_FILE_NAME = \"./data/transcript.txt\"\n",
    "SUBTITLE_FORMAT = \"srt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "FFMPEG_URL = 'https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-win64-gpl.zip'\n",
    "ZIP_PATH = './ffmpeg.zip'\n",
    "EXTRACT_DIR = './'\n",
    "\n",
    "if not os.path.exists(ZIP_PATH):\n",
    "    print('Downloading ffmpeg...')\n",
    "    wget.download(FFMPEG_URL, ZIP_PATH)\n",
    "\n",
    "    print('Unzipping...') \n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_DIR)\n",
    "    \n",
    "    print('Removing zip file...')\n",
    "    os.remove(ZIP_PATH)\n",
    "\n",
    "else:\n",
    "    print('Already downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!yt-dlp -xv --ffmpeg-location ffmpeg-master-latest-win64-gpl/bin --audio-format mp3  -o data/audio/Lex_Podcast -- {\"https://youtu.be/DEu24V8vfb8\"}\n",
    "#!yt-dlp -xv --ffmpeg-location {FFMPEG_LOCATION} --audio-format {AUDIO_FORMAT}  -o {AUDIO_FILE_NAME} -- {\"https://youtu.be/DEu24V8vfb8\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # add .env to .gitignore\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = open(\"data/audio/Lexicap.mp3\", \"rb\")\n",
    "transcript = openai.Audio.transcribe(\"whisper-1\", audio_file, response_format=SUBTITLE_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"langchain.srt\", \"w\") as f:\n",
    "#     f.write(transcript)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longer Inputs\n",
    "By default, the Whisper API only supports files that are less than 25 MB. If you have an audio file that is longer than that, you will need to break it up into chunks of 25 MB's or less or used a compressed audio format. To get the best performance, we suggest that you avoid breaking the audio up mid-sentence as this may cause some context to be lost.\n",
    "\n",
    "One way to handle this is to use the [PyDub open source Python package](https://github.com/jiaaro/pydub) to split the audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "song = AudioSegment.from_mp3(\"good_morning.mp3\")\n",
    "\n",
    "# PyDub handles time in milliseconds\n",
    "ten_minutes = 10 * 60 * 1000\n",
    "\n",
    "first_10_minutes = song[:ten_minutes]\n",
    "\n",
    "first_10_minutes.export(\"good_morning_10.mp3\", format=\"mp3\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompting\n",
    "* Check out [OpenAI](https://platform.openai.com/docs/guides/speech-to-text/prompting)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the transcript with yt-dlp\n",
    "!yt-dlp --write-auto-sub --skip-download --sub-format {SUBTITLE_FORMAT} --sub-lang {SUBTITLE_LANGUAGE} --output {TRANSCRIPT_FILE_NAME} -- {VIDEO_URL}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's change the name of the raw caption files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a clean list of podcast titles\n",
    "import re \n",
    "\n",
    "def clean_titles(title):\n",
    "    title = re.sub(r'\\[(.*?)\\]\\((.*?)\\)', r'\\1', title)\n",
    "    title = re.sub(r'\\|.*?\\d+', '', title)\n",
    "    title = title.rstrip().replace(' ', '_').replace(':', '_').replace('&','and').lower()\n",
    "    title = re.sub(r'[^a-zA-Z0-9_]', '', title)\n",
    "    return title\n",
    "\n",
    "with open('./data/Lexicap.md', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "titles = text.split('\\n')\n",
    "titles = [clean_titles(title) for title in titles if title != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the transcript files\n",
    "import os\n",
    "\n",
    "TRANSCRIPT_PATH = \"./data/transcripts/\"\n",
    "FILE_EXTENSION = '.vtt'\n",
    "\n",
    "for org_filename, line_idx in zip(os.listdir(path=TRANSCRIPT_PATH), titles):\n",
    "    if org_filename.endswith(FILE_EXTENSION):\n",
    "        print(org_filename)\n",
    "        # rename file \n",
    "        new_filename = f\"{line_idx}{FILE_EXTENSION}\"\n",
    "        os.rename(f\"{TRANSCRIPT_PATH}{org_filename}\", f\"{TRANSCRIPT_PATH}{new_filename}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n",
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT_PATH = \"./data/transcripts/\"\n",
    "FILE_EXTENSION = '.vtt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new transcript file with timestamp and text\n",
    "TRANSCRIPT_FILE_NAME = \"45_michio_kaku__future_of_humans_aliens_space_travel_and_physics.vtt\"\n",
    "NEW_TRANSCRIPT_FILE_NAME = \"45_michio_kaku__future_of_humans_aliens_space_travel_and_physics.csv\"\n",
    "\n",
    "\n",
    "with open(f\"{TRANSCRIPT_PATH}{TRANSCRIPT_FILE_NAME}\") as oldfile, open(f\"{NEW_TRANSCRIPT_FILE_NAME}\", 'w') as newfile:\n",
    "    old_lines = oldfile.read().split('\\n')\n",
    "    clean_lines = [line for line in old_lines if line not in ['', 'WEBVTT']]\n",
    "\n",
    "    for line_idx in range(0, len(clean_lines)-1, 2):\n",
    "         timestamp = clean_lines[line_idx].split('-->')[0].strip()\n",
    "         # Standardize timestamp format\n",
    "         timestamp = \"00:\" + timestamp if len(timestamp.split(':')) < 3 else timestamp\n",
    "         timestamp = \"0\" + timestamp if len(timestamp.split(':')[0]) < 2 else timestamp\n",
    "         text = clean_lines[line_idx+1].rstrip()\n",
    "         new_line = f\"{timestamp};{text}\\n\"\n",
    "         newfile.write(new_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>The following is a conversation with Michio Kaku.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:02.800</td>\n",
       "      <td>He's a theoretical physicist, futurist,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:00:05.120</td>\n",
       "      <td>and professor at the City College of New York.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:08.360</td>\n",
       "      <td>He's the author of many fascinating books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00:00:10.760</td>\n",
       "      <td>that explore the nature of our reality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00:00:12.840</td>\n",
       "      <td>and the future of our civilization.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00:00:15.520</td>\n",
       "      <td>They include Einstein's Cosmos, Physics of the Impossible,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00:00:19.200</td>\n",
       "      <td>Future of the Mind, Parallel Worlds,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00:00:21.600</td>\n",
       "      <td>and his latest, The Future of Humanity,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00:00:24.240</td>\n",
       "      <td>Terraforming Mars Interstellar Travel,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>00:00:26.640</td>\n",
       "      <td>Immortality, and Our Destiny Beyond Earth.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00:00:29.960</td>\n",
       "      <td>I think it's beautiful and important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00:00:32.960</td>\n",
       "      <td>when a scientific mind can fearlessly explore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00:00:35.760</td>\n",
       "      <td>through conversation subjects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00:00:37.600</td>\n",
       "      <td>just outside of our understanding.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00:00:40.200</td>\n",
       "      <td>That, to me, is where artificial intelligence is today,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00:00:43.440</td>\n",
       "      <td>just outside of our understanding,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00:00:45.680</td>\n",
       "      <td>a place we have to reach for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00:00:47.440</td>\n",
       "      <td>if we're to uncover the mysteries of the human mind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00:00:50.160</td>\n",
       "      <td>and build human level and superhuman level AI systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00:00:53.880</td>\n",
       "      <td>that transform our world for the better.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00:00:56.640</td>\n",
       "      <td>This is the Artificial Intelligence Podcast.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00:00:59.240</td>\n",
       "      <td>If you enjoy it, subscribe on YouTube,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00:01:01.600</td>\n",
       "      <td>give it five stars on iTunes, support it on Patreon,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00:01:04.640</td>\n",
       "      <td>or simply connect with me on Twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       timestamp                                                         text\n",
       "0   00:00:00.000            The following is a conversation with Michio Kaku.\n",
       "1   00:00:02.800                      He's a theoretical physicist, futurist,\n",
       "2   00:00:05.120               and professor at the City College of New York.\n",
       "3   00:00:08.360                    He's the author of many fascinating books\n",
       "4   00:00:10.760                       that explore the nature of our reality\n",
       "5   00:00:12.840                          and the future of our civilization.\n",
       "6   00:00:15.520   They include Einstein's Cosmos, Physics of the Impossible,\n",
       "7   00:00:19.200                         Future of the Mind, Parallel Worlds,\n",
       "8   00:00:21.600                      and his latest, The Future of Humanity,\n",
       "9   00:00:24.240                       Terraforming Mars Interstellar Travel,\n",
       "10  00:00:26.640                   Immortality, and Our Destiny Beyond Earth.\n",
       "11  00:00:29.960                         I think it's beautiful and important\n",
       "12  00:00:32.960                when a scientific mind can fearlessly explore\n",
       "13  00:00:35.760                                through conversation subjects\n",
       "14  00:00:37.600                           just outside of our understanding.\n",
       "15  00:00:40.200      That, to me, is where artificial intelligence is today,\n",
       "16  00:00:43.440                           just outside of our understanding,\n",
       "17  00:00:45.680                                 a place we have to reach for\n",
       "18  00:00:47.440          if we're to uncover the mysteries of the human mind\n",
       "19  00:00:50.160        and build human level and superhuman level AI systems\n",
       "20  00:00:53.880                     that transform our world for the better.\n",
       "21  00:00:56.640                 This is the Artificial Intelligence Podcast.\n",
       "22  00:00:59.240                       If you enjoy it, subscribe on YouTube,\n",
       "23  00:01:01.600         give it five stars on iTunes, support it on Patreon,\n",
       "24  00:01:04.640                         or simply connect with me on Twitter"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f\"{NEW_TRANSCRIPT_FILE_NAME}\"\n",
    "                            ,sep=';', \n",
    "                            header=None, names=['timestamp', 'text'],)\n",
    "df.head(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Since Whisper has not skipped the punctuations in the transcript, we can reconstruct full sentences, ensuring that each sentence is ended with a period `.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the dataframe with full sentences\n",
    "transcript_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "for idx, timestamp, text in df.itertuples():\n",
    "    while text[-1] != '.':\n",
    "        idx += 1\n",
    "        text += df.loc[idx]['text']\n",
    "    transcript_df = pd.concat([transcript_df, pd.DataFrame({'timestamp': timestamp, 'text': text}, index=[0])], ignore_index=True)\n",
    "\n",
    "# Remove any piece of text if it is included in previous text\n",
    "not_part_of_previous = [True]\n",
    "for i in range(1, len(transcript_df)):\n",
    "    not_part_of_previous.append(transcript_df['text'][i] not in transcript_df['text'][i-1])\n",
    "transcript_df = transcript_df[not_part_of_previous] \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NER\n",
    "* Add column for persons, orginazations, books, companies, countries, places."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mentioned Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "# %pip install -U spaCy\n",
    "# %pip install 'spacy[transformers]'\n",
    "#!python -m spacy download en_core_web_trf # download best-matching version of specific model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('transformer',\n",
       "  <spacy_transformers.pipeline_component.Transformer at 0x2c4ccdfdba0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2c4ccdfdb40>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2c4cce13e40>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2c4cce3dec0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2c4ccdd5b60>)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "# load a pipeline package by name and return nlp object\n",
    "nlp = spacy.load(\"en_core_web_trf\", disable=[\"tok2vec\",\"parser\"]) #disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\", \"ner\"]\n",
    "\n",
    "# check processing pipeline components of nlp object\n",
    "nlp.pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities:  ['Collapse']\n"
     ]
    }
   ],
   "source": [
    "# create a Doc by processing a string of text with the nlp object\n",
    "doc = nlp(\"So I'm with Jared Diamond, you know, in the book Collapse, \\\n",
    "          where he points out studying the collapse of major civilizations, \\\n",
    "          that it often happens right after things appear to never have been better. Hmm.\")\n",
    "\n",
    "\n",
    "# iterate over tokens in a Doc\n",
    "print(\"Entities: \", [e.text for e in doc.ents if e.label_ == 'WORK_OF_ART'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find book related sentences in the transcript\n",
    "book_related_phrases = [\n",
    "    \"book\", \"books\", \"i read\", \n",
    "    \"everyone should read\", \"you should read\", \"he wrote a novel\",\n",
    "    \"i recommend\", \"highly recommend\", \"you must read\", \n",
    "    \"shouldn't miss\", \"top books\", \"best books\", \n",
    "    \"favorite book\", \"my favorite books\", \"book you need to read\",\n",
    "    \"books to read before\", \"essential books\", \"great book for\",\n",
    "    \"worthy read\", \"book of the year\", \"award winning book\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def contains_book_phrase(text: str, search_list: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a text contains any of a list of book-related phrases.\n",
    "\n",
    "    :param text: The text to search within.\n",
    "    :param search_list: A list of phrases to search for.\n",
    "    :return: True if any phrase is found in the text, False otherwise.\n",
    "    \"\"\"\n",
    "    return any(phrase in text.lower() for phrase in search_list)\n",
    "\n",
    "\n",
    "transcript_df[\"is_book_related\"] = transcript_df[\"text\"].apply(contains_book_phrase, search_list=book_related_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_titles_candidates(text: str, pipeline: Callable[[str], 'Doc']) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract potential book titles from a text using a given NLP model.\n",
    "\n",
    "    :param text: The text to extract titles from.\n",
    "    :param pipeline: The NLP model to use for text processing.\n",
    "    :return: A list of potential book titles.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    book_titles_candidates = [entity.text for entity in doc.ents if entity.label_ == 'WORK_OF_ART']\n",
    "    return book_titles_candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3                               []\n",
       "182                             []\n",
       "341                             []\n",
       "478       [The Future of the Mind]\n",
       "638                             []\n",
       "859                             []\n",
       "940                             []\n",
       "954     [The Theory of Everything]\n",
       "957                             []\n",
       "1149          [Future of Humanity]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.query(\"is_book_related == True\")[\"text\"].apply(get_book_titles_candidates,\n",
    "                                                                  pipeline=nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add book candidates to the dataframe\n",
    "transcript_df[\"book_candidates\"] = transcript_df.apply(lambda x: get_book_titles_candidates(x[\"text\"], pipeline=nlp) \\\n",
    "                                                                 if x[\"is_book_related\"] else [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>is_book_related</th>\n",
       "      <th>book_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00:00:08.360</td>\n",
       "      <td>He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>00:08:30.920</td>\n",
       "      <td>And Stephen Hawking, for example, even in his last book, even said that this is an argument against the existence of God.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>00:16:04.760</td>\n",
       "      <td>If you read the book, the aliens did not have evil intentions toward homo sapiens.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>00:22:38.600</td>\n",
       "      <td>I have a book, The Future of the Mind, where I detail some of these breakthroughs.</td>\n",
       "      <td>True</td>\n",
       "      <td>[The Future of the Mind]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>00:29:54.080</td>\n",
       "      <td>Our ancestors were lucky if they had one line, just one line in a church book, saying the date they were baptized and the date they died.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>00:40:07.240</td>\n",
       "      <td>For Isidor Rabi, it was a book about the planets.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>00:44:06.200</td>\n",
       "      <td>That desk had a book on it, which was opened.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>00:44:43.160</td>\n",
       "      <td>And then over the years, I found out the guy had a name, Albert Einstein, and that book was The Theory of Everything.</td>\n",
       "      <td>True</td>\n",
       "      <td>[The Theory of Everything]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>00:44:53.080</td>\n",
       "      <td>Well, today I can read that book.</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>00:53:36.600</td>\n",
       "      <td>And in my book, Future of Humanity, I even speculate beyond that, that by the end of this century, we'll probably have the first starships.</td>\n",
       "      <td>True</td>\n",
       "      <td>[Future of Humanity]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp   \n",
       "3     00:00:08.360  \\\n",
       "182   00:08:30.920   \n",
       "341   00:16:04.760   \n",
       "478   00:22:38.600   \n",
       "638   00:29:54.080   \n",
       "859   00:40:07.240   \n",
       "940   00:44:06.200   \n",
       "954   00:44:43.160   \n",
       "957   00:44:53.080   \n",
       "1149  00:53:36.600   \n",
       "\n",
       "                                                                                                                                              text   \n",
       "3                             He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  \\\n",
       "182                      And Stephen Hawking, for example, even in his last book, even said that this is an argument against the existence of God.   \n",
       "341                                                             If you read the book, the aliens did not have evil intentions toward homo sapiens.   \n",
       "478                                                             I have a book, The Future of the Mind, where I detail some of these breakthroughs.   \n",
       "638      Our ancestors were lucky if they had one line, just one line in a church book, saying the date they were baptized and the date they died.   \n",
       "859                                                                                              For Isidor Rabi, it was a book about the planets.   \n",
       "940                                                                                                  That desk had a book on it, which was opened.   \n",
       "954                          And then over the years, I found out the guy had a name, Albert Einstein, and that book was The Theory of Everything.   \n",
       "957                                                                                                              Well, today I can read that book.   \n",
       "1149   And in my book, Future of Humanity, I even speculate beyond that, that by the end of this century, we'll probably have the first starships.   \n",
       "\n",
       "      is_book_related             book_candidates  \n",
       "3                True                          []  \n",
       "182              True                          []  \n",
       "341              True                          []  \n",
       "478              True    [The Future of the Mind]  \n",
       "638              True                          []  \n",
       "859              True                          []  \n",
       "940              True                          []  \n",
       "954              True  [The Theory of Everything]  \n",
       "957              True                          []  \n",
       "1149             True        [Future of Humanity]  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.query(\"is_book_related == True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'The Hidden Reality',\n",
       " 'subtitle': 'Parallel Universes and the Deep Laws of the Cosmos',\n",
       " 'authors': ['Brian Greene'],\n",
       " 'publisher': 'Penguin UK',\n",
       " 'publishedDate': '2011-06-09',\n",
       " 'description': \"In this exhilarating new book, Brian Greene explores our most current understanding of the universe, its deepest laws of nature, and our continuing quest to know more. The Hidden Reality reveals how major developments in different branches of fundamental theoretical physics-relativistic, quantum, cosmological, unified, computational - have all led us to consider one or another variety of parallel universe. In some, they are separated from us by enormous stretches of space or time, in others they're hovering millimetres away, in others still the very notion of their location proves to be a concept beyond our reach. Most extraordinarily, Greene shows how all of these parallel universe proposals emerge unbidden from the mathematics of theories developed to explain conventional data and observations of the cosmos. This is a life-changing book that gives us a true sense of the astounding possibilities of modern scientific investigation.\",\n",
       " 'industryIdentifiers': [{'type': 'ISBN_13', 'identifier': '9781846145353'},\n",
       "  {'type': 'ISBN_10', 'identifier': '184614535X'}],\n",
       " 'readingModes': {'text': True, 'image': False},\n",
       " 'pageCount': 384,\n",
       " 'printType': 'BOOK',\n",
       " 'categories': ['Science'],\n",
       " 'averageRating': 3.5,\n",
       " 'ratingsCount': 19,\n",
       " 'maturityRating': 'NOT_MATURE',\n",
       " 'allowAnonLogging': True,\n",
       " 'contentVersion': '1.9.8.0.preview.2',\n",
       " 'panelizationSummary': {'containsEpubBubbles': False,\n",
       "  'containsImageBubbles': False},\n",
       " 'imageLinks': {'smallThumbnail': 'http://books.google.com/books/content?id=9q9Jy-TmrWAC&printsec=frontcover&img=1&zoom=5&edge=curl&source=gbs_api',\n",
       "  'thumbnail': 'http://books.google.com/books/content?id=9q9Jy-TmrWAC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api'},\n",
       " 'language': 'en',\n",
       " 'previewLink': 'http://books.google.de/books?id=9q9Jy-TmrWAC&printsec=frontcover&dq=Parallel+Worlds&hl=&cd=6&source=gbs_api',\n",
       " 'infoLink': 'https://play.google.com/store/books/details?id=9q9Jy-TmrWAC&source=gbs_api',\n",
       " 'canonicalVolumeLink': 'https://play.google.com/store/books/details?id=9q9Jy-TmrWAC'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from typing import Optional, Dict\n",
    "\n",
    "def get_book_info(title: str) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch book information from Google Books API.\n",
    "\n",
    "    :param title: The title of the book to search for.\n",
    "    :return: A dictionary containing book information if found, None otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(f\"https://www.googleapis.com/books/v1/volumes?q={title}\")\n",
    "\n",
    "        # Raise an exception if the request was unsuccessful\n",
    "        response.raise_for_status()\n",
    "\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f'HTTP error occurred: {http_err}')\n",
    "        return None\n",
    "    except Exception as err:\n",
    "        print(f'Other error occurred: {err}')\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        data = response.json()\n",
    "        most_rated_book = None\n",
    "        # Find popular book (highest ratings count)\n",
    "        max_ratings_count = -1\n",
    "        for book in data[\"items\"]:\n",
    "            ratings_count = book[\"volumeInfo\"].get(\"ratingsCount\", 0)\n",
    "            if ratings_count > max_ratings_count:\n",
    "                max_ratings_count = ratings_count\n",
    "                most_rated_book = book\n",
    "\n",
    "        if most_rated_book is None:\n",
    "            return None\n",
    "\n",
    "    return most_rated_book[\"volumeInfo\"]\n",
    "# [\"Einstein's Cosmos\",\n",
    "#  'Physics of the Impossible',\n",
    "#  'Future of the Mind',\n",
    "#  'Parallel Worlds',\n",
    "#  'Future of Humanity',\n",
    "#  'Terraforming Mars Interstellar Travel']\n",
    "get_book_info('Parallel Worlds')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Other Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "\n",
    "entity_types = ['PERSON', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'NORP', 'WORK_OF_ART', 'LAW']\n",
    "\n",
    "from typing import List, Optional, Union\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "def extract_entities(doc: Doc, \n",
    "                     include_types: Optional[Union[str, List[str]]] = None, \n",
    "                     sep: str = ' ') -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract named entities from a document and return them as strings.\n",
    "\n",
    "    :param doc: The document to extract entities from.\n",
    "    :param include_types: The types of entities to include. If None, include all types.\n",
    "    :param sep: The separator to use when joining lemmas of multi-token entities.\n",
    "    :return: A list of named entities in the form 'lemma/label'.\n",
    "    \"\"\"\n",
    "    ents = textacy.extract.entities(doc, \n",
    "                                    include_types=include_types, \n",
    "                                    exclude_types=None, \n",
    "                                    drop_determiners=True, \n",
    "                                    min_freq=1)\n",
    "    \n",
    "    return [sep.join([token.text for token in entity])+'/'+entity.label_ for entity in ents]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When processing large volumes of text, it is recommended to use spaCys batch processing for a significant performance gain. The function `nlp.pipeline` takes an iterable of texts, processes them internally as batch, and yields a list fo processed Doc objects in the same order as the input data.\n",
    "* To use `nlp.pipeline`, we first have to define a batch size. Then we can loop over the batches and call `nlp.pipe`. In the inner loop we extract the features from the processed doc and write the values back into the a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:51<00:00,  3.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract entities from the transcript\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 50\n",
    "batches = np.ceil(len(transcript_df) / batch_size).astype(int)\n",
    "\n",
    "named_entities = []\n",
    "\n",
    "# loop over batches, step size is equal to batch size\n",
    "for i in tqdm(range(0, len(transcript_df), batch_size), total=batches):\n",
    "    docs = nlp.pipe(transcript_df['text'][i:i+batch_size])\n",
    "    \n",
    "    for doc in docs:\n",
    "        named_entities.append(extract_entities(doc, include_types=entity_types)) \n",
    "\n",
    "transcript_df['named_entities'] = named_entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entity_type_columns(df, entity_types):\n",
    "    \"\"\"\n",
    "    This function creates new columns in a dataframe for each specified entity type.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The dataframe to modify.\n",
    "    entity_types (List[str]): The entity types to create columns for.\n",
    "    \n",
    "    Returns:\n",
    "    df (pd.DataFrame): The modified dataframe with new entity type columns.\n",
    "    \"\"\"\n",
    "    # Define a function to split entities and group by type\n",
    "    def group_by_type(entities):\n",
    "        grouped_entities = {}\n",
    "        for entity in entities:\n",
    "            name, type_ = entity.split('/')\n",
    "            if type_ in grouped_entities:\n",
    "                grouped_entities[type_].append(name)\n",
    "            else:\n",
    "                grouped_entities[type_] = [name]\n",
    "        return grouped_entities\n",
    "\n",
    "    # Apply function to 'named_entities' and store result in new 'grouped_entities' column\n",
    "    df['grouped_entities'] = df['named_entities'].apply(group_by_type)\n",
    "\n",
    "    # Now for each entity type, just retrieve the list from 'grouped_entities' column\n",
    "    for ent_type in entity_types:\n",
    "        ent_type_lower = ent_type.lower()\n",
    "        df[ent_type_lower] = df['grouped_entities'].apply(lambda x: x.get(ent_type, []))\n",
    "\n",
    "    # We can drop the 'grouped_entities' column after we're done\n",
    "    df = df.drop(columns=['grouped_entities'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_entity_type_columns(transcript_df, entity_types):\n",
    "    \"\"\"\n",
    "    This function creates new columns in a dataframe for each specified entity type.\n",
    "    \n",
    "    Parameters:\n",
    "    transcript_df (pd.DataFrame): The dataframe to modify.\n",
    "    entity_types (List[str]): The entity types to create columns for.\n",
    "    \n",
    "    Returns:\n",
    "    transcript_df (pd.DataFrame): The modified dataframe with new entity type columns.\n",
    "    \"\"\"\n",
    "    # Add columns for each entity type\n",
    "    for ent_type in entity_types:\n",
    "        transcript_df[ent_type.lower()] = transcript_df[\"named_entities\"].apply(lambda x: \\\n",
    "                                                                                [entity.split('/')[0] for entity in x if entity.split('/')[1] == ent_type])\n",
    "    return transcript_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.13 ms ± 275 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# Add columns for each entity type\n",
    "for ent_type in entity_types:\n",
    "    transcript_df[ent_type.lower()] = transcript_df[\"named_entities\"].apply(lambda x: \\\n",
    "                                                                            [entity.split('/')[0] for entity in x if entity.split('/')[1] == ent_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>is_book_related</th>\n",
       "      <th>book_candidates</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>person</th>\n",
       "      <th>org</th>\n",
       "      <th>gpe</th>\n",
       "      <th>loc</th>\n",
       "      <th>product</th>\n",
       "      <th>event</th>\n",
       "      <th>norp</th>\n",
       "      <th>work_of_art</th>\n",
       "      <th>law</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>The following is a conversation with Michio Kaku.</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Michio Kaku/PERSON]</td>\n",
       "      <td>[Michio Kaku]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:02.800</td>\n",
       "      <td>He's a theoretical physicist, futurist, and professor at the City College of New York.</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[City College of New York/ORG]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[City College of New York]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp   \n",
       "0  00:00:00.000  \\\n",
       "1  00:00:02.800   \n",
       "\n",
       "                                                                                      text   \n",
       "0                                        The following is a conversation with Michio Kaku.  \\\n",
       "1   He's a theoretical physicist, futurist, and professor at the City College of New York.   \n",
       "\n",
       "   is_book_related book_candidates                  named_entities   \n",
       "0            False              []            [Michio Kaku/PERSON]  \\\n",
       "1            False              []  [City College of New York/ORG]   \n",
       "\n",
       "          person                         org gpe loc product event norp   \n",
       "0  [Michio Kaku]                          []  []  []      []    []   []  \\\n",
       "1             []  [City College of New York]  []  []      []    []   []   \n",
       "\n",
       "  work_of_art law  \n",
       "0          []  []  \n",
       "1          []  []  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty lists\n",
    "transcript_df = transcript_df.applymap(lambda x: None if isinstance(x, list) and not x else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>is_book_related</th>\n",
       "      <th>book_candidates</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>grouped_entities</th>\n",
       "      <th>person</th>\n",
       "      <th>org</th>\n",
       "      <th>gpe</th>\n",
       "      <th>loc</th>\n",
       "      <th>product</th>\n",
       "      <th>event</th>\n",
       "      <th>norp</th>\n",
       "      <th>work_of_art</th>\n",
       "      <th>law</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>The following is a conversation with Michio Kaku.</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[Michio Kaku/PERSON]</td>\n",
       "      <td>{'PERSON': ['Michio Kaku']}</td>\n",
       "      <td>[Michio Kaku]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:02.800</td>\n",
       "      <td>He's a theoretical physicist, futurist, and professor at the City College of New York.</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>[City College of New York/ORG]</td>\n",
       "      <td>{'ORG': ['City College of New York']}</td>\n",
       "      <td>None</td>\n",
       "      <td>[City College of New York]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp   \n",
       "0  00:00:00.000  \\\n",
       "1  00:00:02.800   \n",
       "\n",
       "                                                                                      text   \n",
       "0                                        The following is a conversation with Michio Kaku.  \\\n",
       "1   He's a theoretical physicist, futurist, and professor at the City College of New York.   \n",
       "\n",
       "   is_book_related book_candidates                  named_entities   \n",
       "0            False            None            [Michio Kaku/PERSON]  \\\n",
       "1            False            None  [City College of New York/ORG]   \n",
       "\n",
       "                        grouped_entities         person   \n",
       "0            {'PERSON': ['Michio Kaku']}  [Michio Kaku]  \\\n",
       "1  {'ORG': ['City College of New York']}           None   \n",
       "\n",
       "                          org   gpe   loc product event  norp work_of_art   \n",
       "0                        None  None  None    None  None  None        None  \\\n",
       "1  [City College of New York]  None  None    None  None  None        None   \n",
       "\n",
       "    law  \n",
       "0  None  \n",
       "1  None  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "import pandas as pd\n",
    "from typing import Optional, Callable\n",
    "\n",
    "def count_words(dataframe: pd.DataFrame, \n",
    "                column: str, \n",
    "                preprocess: Optional[Callable[[str], str]] = None, \n",
    "                min_frequency: int = 1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count words in a specific column of a DataFrame.\n",
    "\n",
    "    :param dataframe: The DataFrame to count words from.\n",
    "    :param column: The column to count words in. Should be tokenized.\n",
    "    :param preprocess: An optional function to preprocess the words before counting.\n",
    "    :param min_frequency: The minimum frequency for a word to be included in the output.\n",
    "    :return: A DataFrame sorted by word frequency, containing words and their frequencies.\n",
    "    \"\"\"\n",
    "    word_counter = Counter()\n",
    "\n",
    "    # If a preprocessing function is provided, apply it before counting words\n",
    "    if preprocess:\n",
    "        dataframe[column].map(lambda doc: word_counter.update(preprocess(doc)))\n",
    "    else:\n",
    "        dataframe[column].map(word_counter.update)\n",
    "\n",
    "    # Convert Counter to DataFrame\n",
    "    word_freq_df = pd.DataFrame.from_dict(word_counter, orient='index', columns=['freq'])\n",
    "    \n",
    "    # Filter words by minimum frequency\n",
    "    word_freq_df = word_freq_df.query('freq >= @min_frequency')\n",
    "    \n",
    "    # Set index name for the dataframe\n",
    "    word_freq_df.index.name = column\n",
    "\n",
    "    # Sort DataFrame by frequency\n",
    "    return word_freq_df.sort_values('freq', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# %pip install WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_word_cloud(data: pd.DataFrame,\n",
    "                        col_name: str, \n",
    "                        max_words: int = 200):\n",
    "    \"\"\"\n",
    "    Generate a word cloud from word frequencies.\n",
    "\n",
    "    :param data: A pandas DataFrame containing text data.\n",
    "    :param col_name: The column name to count words from.\n",
    "    :param max_words: The maximum number of words in the word cloud.\n",
    "    :return: A matplotlib Figure object containing the word cloud or a message indicating no words were found.\n",
    "    \"\"\"\n",
    "    word_frequencies = count_words(data, col_name).freq\n",
    "\n",
    "    # If word_frequencies is empty, return a message\n",
    "    if word_frequencies.empty:\n",
    "        return \"No words found to generate a word cloud.\"\n",
    "\n",
    "    # Convert pandas Series to Counter object\n",
    "    word_frequencies = Counter(word_frequencies.fillna(0).to_dict())\n",
    "\n",
    "    # Create wordcloud object\n",
    "    word_cloud = WordCloud(width=800, height=400, \n",
    "                           background_color= \"black\", colormap=\"Paired\", \n",
    "                           max_font_size=150, max_words=max_words)\n",
    "\n",
    "    # Generate word cloud image from frequencies\n",
    "    word_cloud.generate_from_frequencies(word_frequencies)\n",
    "\n",
    "    # Create new figure\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the cloud using matplotlib \n",
    "    ax.imshow(word_cloud, interpolation='bilinear')\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(col_name.capitalize())\n",
    "\n",
    "    # Return the figure\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = generate_word_cloud(transcript_df, 'law')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No words found to generate a word cloud.'"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: freq, dtype: object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(transcript_df, 'law').freq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q&A\n",
    "## Prepare the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further use in text summariztion and topic modelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSCRIPT_CSV_FILE = \"data\\michio_kaku_transcript_topic.csv\"\n",
    "transcript_df['group'] = transcript_df.index // 8\n",
    "transcript_df_topic = transcript_df.groupby('group').agg({\n",
    "    'timestamp': 'first',\n",
    "    'text': ' '.join\n",
    "})\n",
    "transcript_df_topic.to_csv(TRANSCRIPT_CSV_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For question answering and book identification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_df['group'] = transcript_df.index // 20\n",
    "grouped_transcript_df = transcript_df.groupby('group').agg({\n",
    "    'timestamp': 'first',\n",
    "    'text': ' '.join,\n",
    "    'is_book_related': 'any',\n",
    "    'book_candidates': 'sum',\n",
    "    'named_entities': 'sum',\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will add a new column with that contains identified named-entities in plain text. First, let's create a column with entity dict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities_to_dict(entities):\n",
    "    \"\"\"\n",
    "    This function takes a list of entities in the format \"entity/ENTITY_TYPE\" and returns a dictionary\n",
    "    where the keys are entity types and the values are lists of entities of that type.\n",
    "\n",
    "    Parameters:\n",
    "    entities (list): The input list of entity strings to be processed. Each entity string should be in the format\n",
    "                     \"entity/ENTITY_TYPE\". \n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where the keys are descriptions of entity types (as strings), and the values are lists of \n",
    "          entities (as strings) of the corresponding type. If the input is not a list, returns an empty dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define a mapping from entity types to their descriptions\n",
    "    # entity_type_mapping = {\n",
    "    #     'PERSON': 'People, including fictional',\n",
    "    #     'NORP': 'Nationalities or religious or political groups',\n",
    "    #     'ORG': 'Companies, agencies, and institutions',\n",
    "    #     'GPE': 'Countries, cities, and states',\n",
    "    #     'LOC': 'Non-GPE locations, mountain ranges, bodies of water',\n",
    "    #     'PRODUCT': 'Objects, vehicles, foods, etc. (Not services)',\n",
    "    #     'EVENT': 'Named hurricanes, battles, wars, sports events, etc',\n",
    "    #     'WORK_OF_ART': 'Titles of books, songs, etc',\n",
    "    #     'LAW': 'Named documents made into laws',\n",
    "    # }\n",
    "\n",
    "\n",
    "    if not isinstance(entities, list):\n",
    "        return {}\n",
    "\n",
    "    entities_by_type = {}\n",
    "    for entity in entities:\n",
    "        name, entity_type = entity.split('/')\n",
    "        #Use the mapping to change the keys\n",
    "        # entity_type = entity_type_mapping.get(entity_type, entity_type)\n",
    "        if entity_type not in entities_by_type:\n",
    "            entities_by_type[entity_type] = []\n",
    "        entities_by_type[entity_type].append(name)\n",
    "    return entities_by_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the helper function\n",
    "grouped_transcript_df['named_entities_dict'] = grouped_transcript_df['named_entities'].apply(entities_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>is_book_related</th>\n",
       "      <th>book_candidates</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>named_entities_dict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.  I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>[Michio Kaku/PERSON, City College of New York/ORG, Einstein/PERSON, Cosmos/WORK_OF_ART, Physics of the Impossible/WORK_OF_ART, Future of the Mind/WORK_OF_ART, Parallel Worlds/WORK_OF_ART, Future of Humanity/WORK_OF_ART, Terraforming Mars Interstellar Travel/WORK_OF_ART]</td>\n",
       "      <td>{'PERSON': ['Michio Kaku', 'Einstein'], 'ORG': ['City College of New York'], 'WORK_OF_ART': ['Cosmos', 'Physics of the Impossible', 'Future of the Mind', 'Parallel Worlds', 'Future of Humanity', 'Terraforming Mars Interstellar Travel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:56.640</td>\n",
       "      <td>This is the Artificial Intelligence Podcast.  If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.  And now, here's my conversation with Michio Kaku.  You've mentioned that we just might make contact with aliens or at least hear from them within this century.  Can you elaborate on your intuition behind that optimism? Well, this is pure speculation, of course.  Of course.  Given the fact that we've already identified 4,000 exoplanets orbiting other stars, and we have a census of the Milky Way galaxy for the first time, we know that on average, every single star, on average, has a planet going around it, and about one fifth or so of them have Earth sized planets going around them.</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[Artificial Intelligence Podcast/ORG, YouTube/ORG, iTunes/ORG, Lex Friedman/PERSON, Michio Kaku/PERSON, Milky Way/LOC, Earth/LOC]</td>\n",
       "      <td>{'ORG': ['Artificial Intelligence Podcast', 'YouTube', 'iTunes'], 'PERSON': ['Lex Friedman', 'Michio Kaku'], 'LOC': ['Milky Way', 'Earth']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp   \n",
       "group                 \n",
       "0      00:00:00.000  \\\n",
       "1      00:00:56.640   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text   \n",
       "group                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "0       The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.  I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.  \\\n",
       "1                                                                                               This is the Artificial Intelligence Podcast.  If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.  And now, here's my conversation with Michio Kaku.  You've mentioned that we just might make contact with aliens or at least hear from them within this century.  Can you elaborate on your intuition behind that optimism? Well, this is pure speculation, of course.  Of course.  Given the fact that we've already identified 4,000 exoplanets orbiting other stars, and we have a census of the Milky Way galaxy for the first time, we know that on average, every single star, on average, has a planet going around it, and about one fifth or so of them have Earth sized planets going around them.   \n",
       "\n",
       "       is_book_related book_candidates   \n",
       "group                                    \n",
       "0                 True               0  \\\n",
       "1                False               0   \n",
       "\n",
       "                                                                                                                                                                                                                                                                       named_entities   \n",
       "group                                                                                                                                                                                                                                                                                   \n",
       "0      [Michio Kaku/PERSON, City College of New York/ORG, Einstein/PERSON, Cosmos/WORK_OF_ART, Physics of the Impossible/WORK_OF_ART, Future of the Mind/WORK_OF_ART, Parallel Worlds/WORK_OF_ART, Future of Humanity/WORK_OF_ART, Terraforming Mars Interstellar Travel/WORK_OF_ART]  \\\n",
       "1                                                                                                                                                   [Artificial Intelligence Podcast/ORG, YouTube/ORG, iTunes/ORG, Lex Friedman/PERSON, Michio Kaku/PERSON, Milky Way/LOC, Earth/LOC]   \n",
       "\n",
       "                                                                                                                                                                                                                                named_entities_dict  \n",
       "group                                                                                                                                                                                                                                                \n",
       "0      {'PERSON': ['Michio Kaku', 'Einstein'], 'ORG': ['City College of New York'], 'WORK_OF_ART': ['Cosmos', 'Physics of the Impossible', 'Future of the Mind', 'Parallel Worlds', 'Future of Humanity', 'Terraforming Mars Interstellar Travel']}  \n",
       "1                                                                                                       {'ORG': ['Artificial Intelligence Podcast', 'YouTube', 'iTunes'], 'PERSON': ['Lex Friedman', 'Michio Kaku'], 'LOC': ['Milky Way', 'Earth']}  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_transcript_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to string separated by commas\n",
    "def list_to_str(lst):\n",
    "    \"\"\"\n",
    "    This function takes a list of strings and converts it into a single string, with elements separated by commas.\n",
    "\n",
    "    Parameters:\n",
    "    lst (list or str): The input list or string to be formatted.\n",
    "\n",
    "    Returns:\n",
    "    str: The formatted string if the input is a list of strings, otherwise the input itself.\n",
    "    \"\"\"\n",
    "    if isinstance(lst, list):\n",
    "        if len(lst) > 1:\n",
    "            return ', '.join(lst[:-1]) + ', and ' + lst[-1]\n",
    "        elif lst:\n",
    "            return lst[0]\n",
    "    return lst\n",
    "\n",
    "# Then generate the new 'named_entities' column\n",
    "def entities_plain_txt(row):\n",
    "    \"\"\"\n",
    "    Converts a dictionary of entity types and entities into a plain text.\n",
    "\n",
    "    Parameters:\n",
    "    row (dict): Dictionary where keys are entity types and values are lists of entities.\n",
    "\n",
    "    Returns:\n",
    "    str: A formatted string that lists each entity type and its entities.\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    for entity_type, entities in row.items():\n",
    "        entities_str = list_to_str(entities)\n",
    "        output += f'{entity_type.title()}: {entities_str}\\n'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_transcript_df['named_entities'] = grouped_transcript_df['named_entities_dict'].apply(entities_plain_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>is_book_related</th>\n",
       "      <th>book_candidates</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>named_entities_dict</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.  I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Person: Michio Kaku, and Einstein\\nOrg: City College of New York\\nWork_Of_Art: Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, Future of Humanity, and Terraforming Mars Interstellar Travel\\n</td>\n",
       "      <td>{'PERSON': ['Michio Kaku', 'Einstein'], 'ORG': ['City College of New York'], 'WORK_OF_ART': ['Cosmos', 'Physics of the Impossible', 'Future of the Mind', 'Parallel Worlds', 'Future of Humanity', 'Terraforming Mars Interstellar Travel']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:56.640</td>\n",
       "      <td>This is the Artificial Intelligence Podcast.  If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.  And now, here's my conversation with Michio Kaku.  You've mentioned that we just might make contact with aliens or at least hear from them within this century.  Can you elaborate on your intuition behind that optimism? Well, this is pure speculation, of course.  Of course.  Given the fact that we've already identified 4,000 exoplanets orbiting other stars, and we have a census of the Milky Way galaxy for the first time, we know that on average, every single star, on average, has a planet going around it, and about one fifth or so of them have Earth sized planets going around them.</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Org: Artificial Intelligence Podcast, YouTube, and iTunes\\nPerson: Lex Friedman, and Michio Kaku\\nLoc: Milky Way, and Earth\\n</td>\n",
       "      <td>{'ORG': ['Artificial Intelligence Podcast', 'YouTube', 'iTunes'], 'PERSON': ['Lex Friedman', 'Michio Kaku'], 'LOC': ['Milky Way', 'Earth']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp   \n",
       "group                 \n",
       "0      00:00:00.000  \\\n",
       "1      00:00:56.640   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text   \n",
       "group                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "0       The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.  I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.  \\\n",
       "1                                                                                               This is the Artificial Intelligence Podcast.  If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.  And now, here's my conversation with Michio Kaku.  You've mentioned that we just might make contact with aliens or at least hear from them within this century.  Can you elaborate on your intuition behind that optimism? Well, this is pure speculation, of course.  Of course.  Given the fact that we've already identified 4,000 exoplanets orbiting other stars, and we have a census of the Milky Way galaxy for the first time, we know that on average, every single star, on average, has a planet going around it, and about one fifth or so of them have Earth sized planets going around them.   \n",
       "\n",
       "       is_book_related book_candidates   \n",
       "group                                    \n",
       "0                 True               0  \\\n",
       "1                False               0   \n",
       "\n",
       "                                                                                                                                                                                                               named_entities   \n",
       "group                                                                                                                                                                                                                           \n",
       "0      Person: Michio Kaku, and Einstein\\nOrg: City College of New York\\nWork_Of_Art: Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, Future of Humanity, and Terraforming Mars Interstellar Travel\\n  \\\n",
       "1                                                                                               Org: Artificial Intelligence Podcast, YouTube, and iTunes\\nPerson: Lex Friedman, and Michio Kaku\\nLoc: Milky Way, and Earth\\n   \n",
       "\n",
       "                                                                                                                                                                                                                                named_entities_dict  \n",
       "group                                                                                                                                                                                                                                                \n",
       "0      {'PERSON': ['Michio Kaku', 'Einstein'], 'ORG': ['City College of New York'], 'WORK_OF_ART': ['Cosmos', 'Physics of the Impossible', 'Future of the Mind', 'Parallel Worlds', 'Future of Humanity', 'Terraforming Mars Interstellar Travel']}  \n",
       "1                                                                                                       {'ORG': ['Artificial Intelligence Podcast', 'YouTube', 'iTunes'], 'PERSON': ['Lex Friedman', 'Michio Kaku'], 'LOC': ['Milky Way', 'Earth']}  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_transcript_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate text, named entities, and book candidates into a single column\n",
    "final_text = grouped_transcript_df.apply(lambda row: f\"{row['text']}\\n\\n\" \\\n",
    "                                            f\"Named Entities:\\n{row['named_entities']}\\n\\n\", axis=1)\n",
    "\n",
    "\n",
    "# creating the new DataFrame\n",
    "df_final = pd.DataFrame({\n",
    "    'timestamp': grouped_transcript_df['timestamp'],\n",
    "    'text': final_text\n",
    "})\n",
    "\n",
    "#df_final = grouped_transcript_df[['timestamp', 'text', 'named_entities']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00:00:00.000</td>\n",
       "      <td>The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.  I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.\\n\\nNamed Entities:\\nPerson: Michio Kaku, and Einstein\\nOrg: City College of New York\\nWork_Of_Art: Cosm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00:00:56.640</td>\n",
       "      <td>This is the Artificial Intelligence Podcast.  If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.  And now, here's my conversation with Michio Kaku.  You've mentioned that we just might make contact with aliens or at least hear from them within this century.  Can you elaborate on your intuition behind that optimism? Well, this is pure speculation, of course.  Of course.  Given the fact that we've already identified 4,000 exoplanets orbiting other stars, and we have a census of the Milky Way galaxy for the first time, we know that on average, every single star, on average, has a planet going around it, and about one fifth or so of them have Earth sized planets going around them.\\n\\nNamed Entities:\\nOrg: Artificial Intelligence Podcast, YouTube, and iTunes\\nPerson: Lex Friedman, and Michio Kaku\\nLoc: Milky Way, and Earth\\n\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp   \n",
       "group                 \n",
       "0      00:00:00.000  \\\n",
       "1      00:00:56.640   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text  \n",
       "group                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "0       The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.  I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.\\n\\nNamed Entities:\\nPerson: Michio Kaku, and Einstein\\nOrg: City College of New York\\nWork_Of_Art: Cosm...  \n",
       "1                                                    This is the Artificial Intelligence Podcast.  If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.  And now, here's my conversation with Michio Kaku.  You've mentioned that we just might make contact with aliens or at least hear from them within this century.  Can you elaborate on your intuition behind that optimism? Well, this is pure speculation, of course.  Of course.  Given the fact that we've already identified 4,000 exoplanets orbiting other stars, and we have a census of the Milky Way galaxy for the first time, we know that on average, every single star, on average, has a planet going around it, and about one fifth or so of them have Earth sized planets going around them.\\n\\nNamed Entities:\\nOrg: Artificial Intelligence Podcast, YouTube, and iTunes\\nPerson: Lex Friedman, and Michio Kaku\\nLoc: Milky Way, and Earth\\n\\n\\n  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('data\\michio_kaku_transcript.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quesion answering with LangChain \n",
    "Question answering over documents consists of four steps:\n",
    "\n",
    "1. Create an index : There are three main steps going on after the documents are loaded:\n",
    "    * Splitting documents into chunks \n",
    "    * Creating embeddings for each document\n",
    "    * Storing documents and embeddings in a vectorstore\n",
    "\n",
    "\n",
    "\n",
    "2. Create a Retriever from that index\n",
    "3. Create a question answering chain\n",
    "\n",
    "4. Ask questions!\n",
    "---\n",
    "* See also: \n",
    "    * [LangChain Documentation](https://python.langchain.com/en/latest/modules/indexes/getting_started.html)\n",
    "    * [Medium](https://towardsdatascience.com/4-ways-of-question-answering-in-langchain-188c6707cc5a) \n",
    "    * [LangChain Documentaion](https://python.langchain.com/docs/modules/chains/popular/chat_vector_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # add .env to .gitignore\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader \n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv data with a single row per document.\n",
    "file = 'data\\michio_kaku_transcript.csv'\n",
    "\n",
    "loader = CSVLoader(file_path=file,  encoding='utf-8')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Access data from a specific column\n",
    "# column_data = [doc.page_content['text'] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each document represents one row of the CSV file. Every row is converted into a key/value pair and outputted to a new line in the document’s ``page_content``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"timestamp: 00:00:00.000\\ntext: The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.  I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.\\n\\nNamed Entities:\\nPerson: Michio Kaku, and Einstein\\nOrg: City College of New York\\nWork_Of_Art: Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, Future of Humanity, and Terraforming Mars Interstellar Travel\", metadata={'source': 'data\\\\michio_kaku_transcript.csv', 'row': 0})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``ConversationalRetrievalQA`` chain builds on ``RetrievalQAChain`` to provide a chat history component.\n",
    "\n",
    "It first combines the chat history (either explicitly passed in or retrieved from the provided memory) and the question into a standalone question, then looks up relevant documents from the retriever, and finally passes those documents and the question to a question answering chain to return a response.\n",
    "\n",
    "To create one, you will need a retriever. In the below example, we will create one from a vector store, which can be created from embeddings.\n",
    "\n",
    "> A retriever retrieve the most relevant chunk of text and feed those to the LLM\n",
    "\n",
    "First, let's split the documents, create embeddings for them, and put them in a vectorstore. This allows us to do semantic search over them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1072, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# Select which embeddings we want to use\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vectorstore to use as the index\n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    texts,      # list of documents\n",
    "    embeddings # embedding object\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a memory object, which is neccessary to track the inputs/outputs and hold a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Keep a buffer of all prior messages \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Check out [this notebook](https://github.com/ahmad-alismail/LangChain-for-LLM-Application-Development/blob/master/L2-Memory.ipynb) to learn more about memory in `LangChain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM that recieves a query and generates a response\n",
    "llm = ChatOpenAI(temperature = 0.0, model_name='gpt-3.5-turbo-0613')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize the ``ConversationalRetrievalChain``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa_conversational = ConversationalRetrievalChain.from_llm(llm= llm, # use 'gpt-4'\n",
    "                                                            retriever= db.as_retriever(k=4), # get 4 relevant documents\n",
    "                                                            memory= memory,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the inflationary universe and how it differentiates from the string theory?\"\n",
    "result = qa_conversational({\"question\": query})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The inflationary universe is a theory in physics that suggests that the universe underwent a rapid expansion in its early stages. It proposes that this expansion occurred due to a field called the inflaton field, which caused the universe to expand faster than the speed of light. This theory helps explain certain observations, such as the uniformity of the cosmic microwave background radiation.\n",
       "\n",
       "On the other hand, string theory is a theoretical framework in physics that attempts to unify all the fundamental forces and particles in the universe. It proposes that the fundamental building blocks of the universe are tiny, vibrating strings. These strings give rise to different particles and their interactions. String theory also suggests the existence of multiple dimensions beyond the three spatial dimensions we are familiar with.\n",
       "\n",
       "While both the inflationary universe theory and string theory are attempts to understand the fundamental nature of the universe, they address different aspects. The inflationary universe theory focuses on the early expansion of the universe, while string theory aims to provide a unified description of all the fundamental forces and particles."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What is the inflationary universe and how it differentiates from the string theory?\"\n",
    "result = qa_conversational({\"question\": query})\n",
    "display(Markdown(result[\"answer\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The inflationary universe theory explains the following observations:\n",
       "\n",
       "1. The expansion of the universe: The theory suggests that the universe underwent a rapid expansion in its early stages, known as cosmic inflation, which explains why galaxies are being pushed apart.\n",
       "\n",
       "2. The uniformity of the cosmic microwave background radiation: The theory predicts that the rapid expansion during inflation would have smoothed out any irregularities in the early universe, resulting in the observed uniformity of the cosmic microwave background radiation.\n",
       "\n",
       "3. The large-scale structure of the universe: Inflation provides a mechanism for the formation of the large-scale structure of the universe, such as the distribution of galaxies and galaxy clusters.\n",
       "\n",
       "4. The flatness problem: The theory addresses the flatness problem, which is the observation that the universe appears to be very close to flat on large scales. Inflation predicts that the universe would have started out extremely flat, and the expansion during inflation would have maintained its flatness.\n",
       "\n",
       "It is important to note that the inflationary universe theory is still a subject of ongoing research and investigation, and there may be other observations and phenomena that it can potentially explain."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#chat_history = [(query, result[\"answer\"])]\n",
    "query = \"Which observations are explained by the aforementioned theory?\"\n",
    "result = qa_conversational({\"question\": query})\n",
    "\n",
    "display(Markdown(result[\"answer\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Books Identification\n",
    "\n",
    "Why identifying book titles can be difficult?\n",
    "* The book may contain persons names which are not authors.\n",
    "* The book titles are difficult to identify as such in general. For example \"the Republic\" might or might not be about the book, and if the only indication the model can use is the capitalization it's probably going to make some errors.\n",
    "\n",
    "To be clear, I think it could work to some extent but it would probably make quite a lot of errors.\n",
    "\n",
    "* On the other hand you could obtain a database of books, for instance from Wikipedia (there might be better resources), and you could use this in two ways:\n",
    "\n",
    "1. Directly identify the books/authors in the documents by simple string matching. I would imagine that even if the coverage of the resource is not perfect, this method would easily catch a majority of occurrences.\n",
    "2. In case the above method is not sufficient, it provides you with some good training data from which you could train a NER model in order collect titles which don't exist in the database. Note that there might be issues due to the unknown books being labelled as negative in the training data, so ideally you would have to go manually through the training data and annotate the remaining cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I will use the question answering chain ``load_qa_chain`` (higher cost and possible token limit problem):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0.0)\n",
    "books_chain = load_qa_chain(llm=llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "output_parser = CommaSeparatedListOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all books.\n",
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
     ]
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List all {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "_input = prompt.format(subject=\"books\")\n",
    "print(_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, Future of Humanity, Terraforming Mars Interstellar Travel\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = books_chain.run(input_documents=docs, \n",
    "                     question= _input, \n",
    "                     format_instructions= format_instructions)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Einstein's Cosmos\",\n",
       " 'Physics of the Impossible',\n",
       " 'Future of the Mind',\n",
       " 'Parallel Worlds',\n",
       " 'Future of Humanity',\n",
       " 'Terraforming Mars Interstellar Travel']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse the output to get a list of books\n",
    "books_candidates = output_parser.parse(response)\n",
    "books_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Einstein's Cosmos: How Albert Einstein's Vision Transformed Our Understanding of Space and Time (Great Discoveries)\",\n",
       " 'Parallel Worlds',\n",
       " 'Physics of the Impossible',\n",
       " 'The Future of Humanity',\n",
       " 'The Future of the Mind'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a list of unique book titles\n",
    "books_lst = set([get_book_info(book)['title'] for book in books_candidates])\n",
    "books_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einstein's Cosmos: How Albert Einstein's Vision Transformed Our Understanding of Space and Time (Great Discoveries)\n",
      "Book title: Einstein's Cosmos: How Albert Einstein's Vision Transformed Our Understanding of Space and Time (Great Discoveries)\n",
      "             Author: ['Michio Kaku']\n",
      "             Description: \"A fresh and highly visual tour through Einstein's astonishing legacy.\" —Brian Greene There's no better short book that explains just what Einstein did than Einstein's Cosmos. Keying Einstein's crucial discoveries to the simple mental images that inspired them, Michio Kaku finds a revealing new way to discuss his ideas, and delivers an appealing and always accessible introduction to Einstein's work.\n",
      "             Image: http://books.google.com/books/content?id=YwQl21PeRSwC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api\n",
      "             Link: https://play.google.com/store/books/details?id=YwQl21PeRSwC&source=gbs_api\n",
      "\n",
      "The Future of Humanity\n",
      "Book title: The Future of Humanity\n",
      "             Author: ['Michio Kaku']\n",
      "             Description: Human civilization is on the verge of spreading beyond Earth. More than a possibility, it is becoming a necessity: whether our hand is forced by climate change and resource depletion or whether future catastrophes compel us to abandon Earth, one day we will make our homes among the stars. World-renowned physicist and futurist Michio Kaku explores in rich, accessible detail how humanity might gradually develop a sustainable civilization in outer space. With his trademark storytelling verve, Kaku shows us how science fiction is becoming reality: mind-boggling developments in robotics, nanotechnology, and biotechnology could enable us to build habitable cities on Mars; nearby stars might be reached by microscopic spaceships sailing through space on laser beams; and technology might one day allow us to transcend our physical bodies entirely. With irrepressible enthusiasm and wonder, Dr. Kaku takes readers on a fascinating journey to a future in which humanity could finally fulfil its long-awaited destiny among the stars - and perhaps even achieve immortality.\n",
      "             Image: http://books.google.com/books/content?id=fSw6DwAAQBAJ&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api\n",
      "             Link: https://play.google.com/store/books/details?id=fSw6DwAAQBAJ&source=gbs_api\n",
      "\n",
      "The Future of the Mind\n",
      "Book title: The Future of the Mind\n",
      "             Author: ['Michio Kaku']\n",
      "             Description: Recording memories, mind reading, videotaping our dreams, mind control, avatars, and telekinesis - no longer are these feats of the mind solely the province of overheated science fiction. As Michio Kaku reveals, not only are they possible, but with the latest advances in brain science and recent astonishing breakthroughs in technology, they already exist. In The Future of the Mind, the New York Times-bestselling author takes us on a stunning, provocative and exhilarating tour of the top laboratories around the world to meet the scientists who are already revolutionising the way we think about the brain - and ourselves.\n",
      "             Image: http://books.google.com/books/content?id=YPFevgEACAAJ&printsec=frontcover&img=1&zoom=1&source=gbs_api\n",
      "             Link: http://books.google.de/books?id=YPFevgEACAAJ&dq=The+Future+of+the+Mind&hl=&source=gbs_api\n",
      "\n",
      "Parallel Worlds\n",
      "Book title: Parallel Worlds\n",
      "             Author: ['Michio Kaku']\n",
      "             Description: Sheds new light on discoveries that have revolutionized the field of cosmology and transformed understanding of the universe, offering an explanation of the multiverse M-theory and its implications in terms of the fate of our own universe.\n",
      "             Image: http://books.google.com/books/content?id=21NGAAAAYAAJ&printsec=frontcover&img=1&zoom=1&source=gbs_api\n",
      "             Link: http://books.google.de/books?id=21NGAAAAYAAJ&dq=Parallel+Worlds&hl=&source=gbs_api\n",
      "\n",
      "Physics of the Impossible\n",
      "Book title: Physics of the Impossible\n",
      "             Author: ['Michio Kaku']\n",
      "             Description: Physics of the Impossible takes us on a journey to the frontiers of science and beyond, giving us an exhilarating insight into what we can really hope to achieve in the future. Everyday we see that what was once declared 'impossible' by scientists has become part of our everyday lives: fax machines, glass sky-scrapers, gas-powered automobiles and a worldwide communications network. Here internationally bestselling author Micho Kaku confidently hurdles today's frontier of science, revealing the actual possibilities of perpetual motion, force fields, invisibility, ray guns, anti-gravity and anti-matter, teleportation, telepathy, psychokinesis, robots and cyborgs, time travel, zero-point energy, even extraterrestrial life. And he shows how few of these ideas actually violate the laws of physics. Where does the realm of science fiction end? What can we really hope to achieve? 'Anything that is not impossible, is mandatory!' declares Kaku in this lucid, entertaining and enlightening read.\n",
      "             Image: http://books.google.com/books/content?id=zmmQMPAVkxgC&printsec=frontcover&img=1&zoom=1&edge=curl&source=gbs_api\n",
      "             Link: https://play.google.com/store/books/details?id=zmmQMPAVkxgC&source=gbs_api\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for book in books_lst:\n",
    "    print(book)\n",
    "    book_info = get_book_info(book)\n",
    "    print(f\"Book title: {book_info['title']}\\n \\\n",
    "            Author: {book_info['authors']}\\n \\\n",
    "            Description: {book_info['description']}\\n \\\n",
    "            Image: {book_info['imageLinks'].get('thumbnail', 'smallThumbnail')}\\n \\\n",
    "            Link: {book_info['infoLink']}\\n\"\n",
    "    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Key issues: \n",
    "    * Context limit (try to use ``as_retriver(k=4)``)\n",
    "    * `get_book_info` function is not stable (e.g., parallel worlds)\n",
    "* Further development: Use sequential chain to create markdown tables from the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization\n",
    "If you're working with several pages that require summarization, you might encounter a token limit. While these restrictions won't always pose a challenge, it's beneficial to understand how to navigate them when they arise.\n",
    "\n",
    "In dealing with this, the ``map_reduce`` chain type serves as a helpful tool. Initially, you create a summary of smaller parts that are within the token limitation, followed by generating a summary that encapsulates these individual summaries.\n",
    "\n",
    "---\n",
    "* [Workaround OpenAI's Token Limit Chain Types](https://www.youtube.com/watch?v=f9_BWhCI4Zo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM that recieves a query and generates a response\n",
    "llm = ChatOpenAI(temperature = 0.0, model_name='gpt-3.5-turbo-0613') # or  'gpt-3.5-turbo-16k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "TRANSCRIPT_CSV_FILE = 'data\\michio_kaku_transcript_topic.csv'\n",
    "\n",
    "with open(TRANSCRIPT_CSV_FILE) as file:\n",
    "    full_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13043"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the number of tokens in the transcript\n",
    "llm.get_num_tokens(full_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's too many, let's split our text up into chunks. We do this so:\n",
    "\n",
    "1. The context size is smaller and the LLM can increase it's attention to context ratio\n",
    "2. In case the text is too long and it wouldn't fit in the prompt anyway\n",
    "\n",
    "I will choose a chunk size of 10,000 characters so they fit the prompt limit.\n",
    "\n",
    "> You can think of tokens as pieces of words used for natural language processing. For English text, 1 token is approximately 4 characters or 0.75 words. As a point of reference, the collected works of Shakespeare are about 900,000 words or 1.2M tokens.\n",
    "\n",
    "This means the number of tokens we should expect is 10,000 / 4 = ~2,500 token chunks. But this will vary, each body of text/code will be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=10000, chunk_overlap=500)\n",
    "\n",
    "splitted_texts = text_splitter.create_documents([full_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now we have 6 documents and the first one has 2331 tokens\n"
     ]
    }
   ],
   "source": [
    "num_docs = len(splitted_texts)\n",
    "\n",
    "num_tokens_first_doc = llm.get_num_tokens(splitted_texts[0].page_content)\n",
    "\n",
    "print (f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, assuming that number of tokens is consistent in the other docs we should be good to go. Let's use LangChain's ``load_summarize_chain`` to do the ``map_reducing`` for us. We first need to initialize our chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_prompt = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes:\n",
    "\n",
    "```{text}```\n",
    "\n",
    "- Capture the main points, themes, and key takeaways of the text.\n",
    "- Ensure to include the most significant arguments, insights, and conclusions drawn from the text.\n",
    "- Ensure to include the timestamp when the spakers started talking about the main point.\n",
    "- Only respond with the timestamp and the concise summary, nothing else. \n",
    "\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "map_prompt_template = PromptTemplate.from_template(map_prompt) # infer input variables automatically\n",
    "\n",
    "\n",
    "combine_prompt = \"\"\"\n",
    "Write a concise summary of the following text delimited by triple backquotes.\n",
    "\n",
    "Return your response in bullet points which covers the key points of the text and \\\n",
    "    the timestamp when the spakers started talking about the main point. \n",
    "```{text}```\n",
    "BULLET POINT SUMMARY:\n",
    "\"\"\"\n",
    "combine_prompt_template = PromptTemplate.from_template(combine_prompt) # infer input variables automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The ``map_prompt`` and ``combine_prompt`` are parameters used in the ``load_summarize_chain`` function of the LangChain library.\n",
    "\n",
    "> The ``map_prompt`` is used to specify the prompt template for the map step in the summarization chain. It is a string that contains placeholders for the input text, and it is used to generate intermediate summaries for each document.\n",
    "\n",
    "> The ``combine_prompt`` is used to specify the prompt template for the combine step in the summarization chain. It is a string that contains placeholders for the intermediate summaries, and it is used to generate the final summary by combining the intermediate summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_chain = load_summarize_chain(llm=llm,\n",
    "                                     chain_type='map_reduce',\n",
    "                                     map_prompt=map_prompt_template,\n",
    "                                     combine_prompt=combine_prompt_template,\n",
    "                                      verbose=True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text delimited by triple backquotes:\n",
      "\n",
      "```timestamp,text\n",
      "00:00:00.000,\" The following is a conversation with Michio Kaku.  He's a theoretical physicist, futurist, and professor at the City College of New York.  He's the author of many fascinating books that explore the nature of our reality and the future of our civilization.  They include Einstein's Cosmos, Physics of the Impossible, Future of the Mind, Parallel Worlds, and his latest, The Future of Humanity, Terraforming Mars Interstellar Travel, Immortality, and Our Destiny Beyond Earth.\"\n",
      "00:00:29.960,\" I think it's beautiful and important when a scientific mind can fearlessly explore through conversation subjects just outside of our understanding.  That, to me, is where artificial intelligence is today, just outside of our understanding, a place we have to reach for if we're to uncover the mysteries of the human mind and build human level and superhuman level AI systems that transform our world for the better.\"\n",
      "00:00:56.640,\" This is the Artificial Intelligence Podcast.  If you enjoy it, subscribe on YouTube, give it five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex Friedman, spelled F R I D M A N.\"\n",
      "00:01:09.920,\" And now, here's my conversation with Michio Kaku.  You've mentioned that we just might make contact with aliens or at least hear from them within this century.  Can you elaborate on your intuition behind that optimism? Well, this is pure speculation, of course.  Of course.\"\n",
      "00:01:28.960,\" Given the fact that we've already identified 4,000 exoplanets orbiting other stars, and we have a census of the Milky Way galaxy for the first time, we know that on average, every single star, on average, has a planet going around it, and about one fifth or so of them have Earth sized planets going around them.\"\n",
      "00:01:51.240,\" So just do the math.  We're talking about out of 100 billion stars in the Milky Way galaxy, we're talking about billions of potential Earth sized planets.  And to believe that we're the only one is, I think, rather ridiculous, given the odds.  And how many galaxies are there? Within sight of the Hubble Space Telescope, there are about 100 billion galaxies.\"\n",
      "00:02:17.880,\" So do the math.  How many stars are there in the visible universe? 100 billion galaxies, times 100 billion stars per galaxy.  We're talking about a number beyond human imagination.  And to believe that we're the only ones, I think, is rather ridiculous.\"\n",
      "00:02:38.200,\" So you've talked about different types of, type zero, one, two, three, four, and five, even, of the Kardashev scale of the different kind of civilizations.  What do you think it takes, if it is indeed a ridiculous notion that we're alone in the universe, what do you think it takes to reach out? First, to reach out through communication and connect.\"\n",
      "00:03:02.660,\" Well, first of all, we have to understand the level of sophistication of an alien life form if we make contact with them.  I think in this century, we'll probably pick up signals, signals from an extraterrestrial civilization.  We'll pick up there, I love Lucy, and there, leave it to Beaver.\"\n",
      "00:03:21.280,\" Just ordinary day to day transmissions that they emit.  And the first thing we wanna do is to A, decipher their language, of course, but B, figure out at what level they are advanced on the Kardashev scale.  I'm a physicist.\"\n",
      "00:03:38.560,\" We rank things by two parameters, energy and information.  That's how we rank black holes.  That's how we rank stars.  That's how we rank civilizations in outer space.  So a type one civilization is capable of harnessing planetary power.  They control the weather, for example, earthquakes, volcanoes.  They can modify the course of geological events, sort of like Flash Gordon or Buck Rogers.\"\n",
      "00:04:08.400,\" Type two would be stellar.  They play with stars, entire stars.  They use the entire energy output of a star, sort of like Star Trek.  The Federation of Planets have colonized the nearby stars.  So a type two would be somewhat similar to Star Trek.  Type three would be galactic.\"\n",
      "00:04:30.660,\" They roam the galactic space lanes.  And type three would be like Star Wars, a galactic civilization.  Now, one day I was giving this talk in London at the planetarium there, and the little boy comes up to me and he says, professor, you're wrong.  You're wrong, there's type four.  And I told him, look, kid, there are planets, stars, and galaxies.\"\n",
      "00:04:57.000,\" That's it, folks.  And he kept persisting and saying, no, there's type four, the power of the continuum.  And I thought about it for a moment.  And I said to myself, is there an extra galactic source of energy, the continuum of Star Trek? And the answer is yes, there could be a type four.\"\n",
      "00:05:18.080,\" And that's dark energy.  We now know that 73% of the energy of the universe is dark energy.  Dark matter represents maybe 23% or so, and we only represent 4%.  We're the oddballs.  And so you begin to realize that, yeah, there could be type four, maybe even type five.\"\n",
      "00:05:39.760,\" So type four, you're saying being able to harness sort of like dark energy, something that permeates the entire universe.  So be able to plug into the entire universe as a source of energy.  That's right.  And dark energy is the energy of the Big Bang.\"\n",
      "00:05:55.680,\" It's why the galaxies are being pushed apart.  It's the energy of nothing.  The more nothing you have, the more dark energy that's repulsive.  And so the acceleration of the universe is accelerating because the more you have, the more you can have.  And that, of course, is by definition an exponential curve.  It's called a de Sitter expansion, and that's the current state of the universe.\"\n",
      "00:06:20.480,\" And then type five, would that be able to seek energy sources somehow outside of our universe? And how crazy is that idea? Yeah, type five will be the multiverse.  Multiverse, okay.  I'm a quantum physicist, and we quantum physicists don't believe that the Big Bang happened once.\"\n",
      "00:06:42.120,\" That would violate the Heisenberg uncertainty principle.  And that means that there could be multiple bangs happening all the time.  Even as we speak today, universes are being created, and that fits the data.  The inflationary universe is a quantum theory.  So there's a certain finite probability that universes are being created all the time.\"\n",
      "00:07:05.120,\" And for me, this is actually rather aesthetically pleasing because I was raised as a Presbyterian, but my parents were Buddhists.  And there's two diametrically opposed ideas about the universe.  In Buddhism, there's only nirvana.  There's no beginning, there's no end, there's only timelessness.\"\n",
      "00:07:26.940,\" But in Christianity, there is the instant when God said, let there be light.  In other words, an instant of creation.  So I've had these two mutually exclusive ideas in my head, and I now realize that it's possible to meld them into a single theory.  Either the universe had a beginning or it didn't, right? Wrong.\"\n",
      "00:07:49.880,\" You see, our universe had a beginning.  Our universe had an instant where somebody might have said, let there be light.  But there are other bubble universes out there in a bubble bath of universes.  And that means that these universes are expanding into a dimension beyond our three dimensional comprehension.\"\n",
      "00:08:11.240,\" In other words, hyperspace.  In other words, 11 dimensional hyperspace.  So nirvana would be this timeless 11 dimensional hyperspace where big bangs are happening all the time.  So we can now combine two mutually exclusive theories of creation.  And Stephen Hawking, for example, even in his last book, even said that this is an argument against the existence of God.\"\n",
      "00:08:39.320,\" He said there is no God because there was not enough time for God to create the universe because the big bang happened in an instant of time.  Therefore, there was no time available for him to create the universe.  But you see, the multiverse idea means that there was a time before time.\"\n",
      "00:08:58.040,\" And there are multiple times, each bubble has its own time.  And so it means that there could actually be a universe before the beginning of our universe.  So if you think of a bubble bath, when two bubbles collide, or when two bubbles fission to create a baby bubble, that's called the big bang.  So the big bang is nothing but the collision of universes or the budding of universes.\"\n",
      "00:09:23.720,\" That's such a beautiful picture of our incredibly mysterious existence.  So is that humbling to you? Exciting, the idea of multiverses? I don't even know how to even begin to wrap my mind around it.  It's exciting for me because what I do for a living is string theory.\"\n",
      "00:09:41.680,\" That's my day job.  I get paid by the city of New York to work on string theory.  And you see, string theory is a multiverse theory.  So people say, first of all, what is string theory? String theory simply says that all the particles we see in nature, the electron, the proton, the quarks, what have you, are nothing but vibrations on a musical string, on a tiny, tiny little string.\"\n",
      "00:10:05.920,\" You know, G. Robert Oppenheimer, the creator of the atomic bomb, was so frustrated in the 1950s with all these subatomic particles being created in our atom smashers that he announced, he announced one day that the Nobel Prize in physics should go to the physicist who does not discover a new particle that year.\"\n",
      "00:10:28.280,\" Well, today we think they're nothing but musical notes on these tiny little vibrating strings.  So what is physics? Physics is the harmonies you can write on vibrating strings.  What is chemistry? Chemistry is the melodies you can play on these strings.  What is the universe? The universe is a symphony of strings.\"```\n",
      "\n",
      "- Capture the main points, themes, and key takeaways of the text.\n",
      "- Ensure to include the most significant arguments, insights, and conclusions drawn from the text.\n",
      "- Ensure to include the timestamp when the spakers started talking about the main point.\n",
      "- Only respond with the timestamp and the concise summary, nothing else. \n",
      "\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text delimited by triple backquotes:\n",
      "\n",
      "```00:10:28.280,\" Well, today we think they're nothing but musical notes on these tiny little vibrating strings.  So what is physics? Physics is the harmonies you can write on vibrating strings.  What is chemistry? Chemistry is the melodies you can play on these strings.  What is the universe? The universe is a symphony of strings.\"\n",
      "00:10:50.280,\" And then what is the mind of God that Albert Einstein so eloquently wrote about for the last 30 years of his life? The mind of God would be cosmic music, resonating through 11 dimensional hyperspace.  So beautifully put.  What do you think is the mind of Einstein's God? Do you think there's a why that we could untangle from this universe of strings? Why are we here? What is the meaning of it all? Well, Steven Weinberg, winner of the Nobel Prize, once said that the more we learn about the universe, the more we learn that it's pointless.\"\n",
      "00:11:32.240,\" Well, I don't know.\"\n",
      "00:11:35.600,\" I don't profess to understand the great secrets of the universe.  However, let me say two things about what the giants of physics have said about this question.  Einstein believed in two types of God.  One was the God of the Bible, the personal God, the God that answers prayers, walks on waters, performs miracles, smites the Philistines.\"\n",
      "00:12:00.040,\" That's the personal God that he didn't believe in.  He believed in the God of Spinoza, the God of order, simplicity, harmony, beauty.  The universe could have been ugly.  The universe could have been messy, random, but it's gorgeous.  You realize that on a single sheet of paper, we can write down all the known laws of the universe.\"\n",
      "00:12:23.120,\" It's amazing, on one sheet of paper, Einstein's equation is one inch long, string theory is a lot longer, and so it's a standard model, but you could put all these equations on one sheet of paper.  It didn't have to be that way.\"\n",
      "00:12:38.640,\" It could have been messy.  And so, Einstein thought of himself as a young boy entering this huge library for the first time, being overwhelmed by the simplicity, elegance, and beauty of this library, but all he could do was read the first page of the first volume.  Well, that library is the universe, with all sorts of mysterious, magical things that we have yet to find.\"\n",
      "00:13:05.280,\" And then Galileo was asked about this.  Galileo said that the purpose of science, the purpose of science is to determine how the heavens go.  The purpose of religion is to determine how to go to heaven.  So in other words, science is about natural law, and religion is about ethics, how to be a good person, how to go to heaven.\"\n",
      "00:13:32.320,\" As long as we keep these two things apart, we're in great shape.  The problem occurs when people from the natural sciences begin to pontificate about ethics, and people from religion begin to pontificate about natural law.\"\n",
      "00:13:47.880,\" That's where we get into big trouble.  You think they're fundamentally distinct, morality and ethics and our idea of what is right and what is wrong.  That's something that's outside the reach of string theory and physics.  That's right.  If you talk to a squirrel about what is right and what is wrong, there's no reference frame for a squirrel, and realize that aliens from outer space, if they ever come visit us, they'll try to talk to us like we talk to squirrels in the forest, but eventually we get bored talking to the squirrels because they don't talk back to us.\"\n",
      "00:14:28.040,\" Same thing with aliens from outer space.  They come down to earth, they'll be curious about us to a degree, but after a while they just get bored because we have nothing to offer them.\"\n",
      "00:14:37.920,\" So our sense of right and wrong, what does that mean compared to a squirrel's sense of right and wrong? Now we of course do have an ethics that keeps civilizations in line, enriches our life and makes civilization possible.\"\n",
      "00:14:56.480,\" And I think that's a good thing, but it's not mandated by a law of physics.  So if aliens do, alien species were to make contact, forgive me for staying on aliens for a bit longer.  Do you think they're more likely to be friendly, to befriend us or to destroy us? Well, I think for the most part, they'll pretty much ignore us.\"\n",
      "00:15:22.880,\" If you're a deer in the forest, who do you fear the most? Do you fear the hunter with his gigantic 16 gauge shotgun? Or do you fear the guy with a briefcase and glasses? Well, the guy with the briefcase could be a developer about to basically flatten the entire forest, destroying your livelihood.  So instinctively you may be afraid of the hunter, but actually the problem with deers in the forest is that they should fear developers because developers look at deer as simply getting in the way.\"\n",
      "00:15:59.440,\" I mean, in War of the Worlds by H.G. Wells, the aliens did not hate us.  If you read the book, the aliens did not have evil intentions toward homo sapiens.  No, we were in the way.\"\n",
      "00:16:13.560,\" So I think we have to realize that alien civilizations may view us quite differently than in science fiction novels.  However, I personally believe, and I cannot prove any of this, I personally believe that they're probably gonna be peaceful because there's nothing that they want from our world.  I mean, what are they gonna take us? What are they gonna take us for, gold? No, gold is a useless metal for the most part.\"\n",
      "00:16:39.360,\" It's silver, I mean, it's gold in color, but that only affects homo sapiens.  Squirrels don't care about gold.  And so gold is a rather useless element.  Rare earths maybe, platinum based elements, rare earths for the electronics, yeah, maybe.  But other than that, we have nothing to offer them.\"\n",
      "00:16:59.280,\" I mean, think about it for a moment.  People love Shakespeare and they love the arts and poetry, but outside of the earth, they mean nothing, absolutely nothing.  I mean, when I write down an equation in string theory, I would hope that on the other side of the galaxy, there's an alien writing down that very same equation in different notation, but that alien on the other side of the galaxy, Shakespeare, poetry, Hemingway, it would mean nothing to him or her or it.\"\n",
      "00:17:33.960,\" When you think about entities that's out there, extraterrestrial, do you think they would naturally look something that even is recognizable to us as life? Or would they be radically different? Well, how did we become intelligent? Basically three things made us intelligent.\"\n",
      "00:17:56.160,\" One is our eyesight, stereo eyesight.  We have the eyes of a hunter, stereo vision so we lock in on targets.  And who is smarter, predator or prey? Predators are smarter than prey.  They have their eyes at the front of their face, like lions, tigers, while rabbits have eyes to the side of their face.\"\n",
      "00:18:18.800,\" Why is that? Hunters have to zero in on the target.  They have to know how to ambush.  They have to know how to hide, camouflage, sneak up, stealth, deceit.  That takes a lot of intelligence.  Rabbits, all they have to do is run.\"\n",
      "00:18:35.200,\" So that's the first criterion, stereo eyesight of some sort.  Second is the thumb.  The opposable thumb of some sort could be a claw or a tentacle.  So hand eye coordination.  Hand eye coordination is the way we manipulate the environment.  And then three, language.\"\n",
      "00:18:55.040,\" Because mama bear never tells baby bear to avoid the human hunter.  Bears just learn by themselves.  They never hand out information from one generation to the next.  So these are the three basic ingredients of intelligence.  Eyesight of some sort, an opposable thumb or tentacle or claw of some sort, and language.\"\n",
      "00:19:16.640,\" Now ask yourself a simple question.  How many animals have all three? Just us.  It's just us.  I mean, the primates, they have a language, yeah, they may get up to maybe 20 words, but a baby learns a word a day, several words a day a baby learns.\"\n",
      "00:19:35.120,\" And a typical adult knows about almost 5,000 words.  While the maximum number of words that you can teach a gorilla in any language, including their own language, is about 20 or so.  And so we see the difference in intelligence.  So when we meet aliens from outer space, chances are they will have been descended from predators of some sort.\"\n",
      "00:20:01.040,\" They'll have some way to manipulate the environment and communicate their knowledge to the next generation.  That's it, folks.  So functionally, that would be similar.  That would, we would be able to recognize them.  Well, not necessarily, because I think even with Homo sapiens, we are eventually going to perhaps become part cybernetic and genetically enhanced.\"\n",
      "00:20:27.960,\" Already, robots are getting smarter and smarter.  Right now, robots have the intelligence of a cockroach.  But in the coming years, our robots will be as smart as a mouse, then maybe as smart as a rabbit.  If we're lucky, maybe as smart as a cat or a dog.  And by the end of the century, who knows for sure, our robots will be probably as smart as a monkey.\"\n",
      "00:20:53.680,\" Now, at that point, of course, they could be dangerous.  You see, monkeys are self aware.  They know they are monkeys.  They may have a different agenda than us.  While dogs, dogs are confused.  You see, dogs think that we are a dog, that we're the top dog.\"\n",
      "00:21:16.360,\" They're the underdog.  That's why they whimper and follow us and lick us all the time.  We're the top dog.  Monkeys have no illusion at all.  They know we are not monkeys.  And so I think that in the future, we'll have to put a chip in their brain to shut them off once our robots have murderous thoughts.\"\n",
      "00:21:35.480,\" But that's in a hundred years.  In 200 years, the robots will be smart enough to remove that fail safe chip in their brain and then watch out.  At that point, I think rather than compete with our robots, we should merge with them.  We should become part cybernetic.\"```\n",
      "\n",
      "- Capture the main points, themes, and key takeaways of the text.\n",
      "- Ensure to include the most significant arguments, insights, and conclusions drawn from the text.\n",
      "- Ensure to include the timestamp when the spakers started talking about the main point.\n",
      "- Only respond with the timestamp and the concise summary, nothing else. \n",
      "\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text delimited by triple backquotes:\n",
      "\n",
      "```00:21:35.480,\" But that's in a hundred years.  In 200 years, the robots will be smart enough to remove that fail safe chip in their brain and then watch out.  At that point, I think rather than compete with our robots, we should merge with them.  We should become part cybernetic.\"\n",
      "00:21:56.800,\" So I think when we meet alien life from outer space, they may be genetically and cybernetically enhanced.  Genetically and cybernetically enhanced.  Wow, so let's talk about that full range.  In the near term and 200 years from now, how promising in the near term in your view is brain machine interfaces? So starting to allow computers to talk directly to the brains, Elon Musk is working on that with Neuralink and there's other companies working on this idea.\"\n",
      "00:22:29.000,\" Do you see promise there? Do you see hope for near term impact? Well, every technology has pluses and minuses.  Already we can record memories.  I have a book, The Future of the Mind, where I detail some of these breakthroughs.\"\n",
      "00:22:42.840,\" We can now record simple memories of mice and send these memories on the internet.  Eventually, we're gonna do this with primates at Wake Forest University and also in Los Angeles.  And then after that, we'll have a memory chip for Alzheimer's patients.  We'll test it out in Alzheimer's patients because of course, when Alzheimer's patients lose their memory, they wander.\"\n",
      "00:23:07.760,\" They create all sorts of havoc, wandering around, oblivious to their surroundings and they'll have a chip.  They'll push the button and memories, memories will come flooding into their hippocampus and the chip telling them where they live and who they are.  And so a memory chip is definitely in the cards.  And I think this will eventually affect human civilization.\"\n",
      "00:23:33.200,\" What is the future of the internet? The future of the internet is brain net.  Brain net is when we send emotions, feelings, sensations on the internet.  And we will telepathically communicate with other humans this way.  This is gonna affect everything.  Look at entertainment.\"\n",
      "00:23:52.480,\" Remember the silent movies? Charlie Chaplin was very famous during the era of silent movies.  But when the talkies came in, nobody wanted to see Charlie Chaplin anymore because he never talked in the movies.  And so a whole generation of actors lost their job and a new series of actors came in.\"\n",
      "00:24:11.400,\" Next, we're gonna have the movies replaced by brain net because in the future, people will say, who wants to see a screen with images? That's it.  Sound and image, that's called the movies.  In our entertainment industry, this multi billion dollar industry is based on screens with moving images and sound.\"\n",
      "00:24:34.680,\" But what happens when emotions, feelings, sensations, memories can be conveyed on the internet? It's gonna change everything.  Human relations will change because you'll be able to empathize and feel the suffering of other people.  We'll be able to communicate telepathically.  And this is coming.\"\n",
      "00:24:55.880,\" You described brain net and future of the mind.  This is an interesting concept.  Do you think, so you mentioned entertainment, but what kind of effect would it have on our personal relationships? Hopefully it will deepen it.  You realize that for most of human history, for over 90% of human history, we only knew maybe 20, 100 people.\"\n",
      "00:25:22.040,\" That's it, folks.  That was your tribe.  That was everybody you knew in the universe was only maybe 50 or 100.  With the coming of towns, of course it expanded to a few thousand.  With the coming of the telephone, all of a sudden you could reach thousands of people with a telephone.\"\n",
      "00:25:41.600,\" And now with the internet, you can reach the entire population of the planet Earth.  And so I think this is a normal progression.  And you think that kind of sort of connection to the rest of the world, and then adding sensations like being able to share telepathically emotions and so on that would just further deepen our connection to our fellow humans.\"\n",
      "00:26:02.920,\" That's right.  In fact, I disagree with many scientists on this question.  Most scientists would say that technology is neutral.  A double edged sword, one side of the sword can cut against people.\"\n",
      "00:26:15.960,\" The other side of the sword can cut against ignorance and disease.  I disagree.  I think technology does have a moral direction.  Look at the internet.  The internet spreads knowledge, awareness, and that creates empowerment.  People act on knowledge.\"\n",
      "00:26:35.400,\" When they begin to realize that they don't have to live that way, they don't have to suffer under a dictatorship, that there are other ways of living under freedom, then they begin to take things, take power.  And that spreads democracy.  And democracies do not war with other democracies.  I'm a scientist.\"\n",
      "00:26:55.240,\" I believe in data.  So let's take a sheet of paper and write down every single war you had to learn since you were in elementary school.  Every single war, hundreds of them.  Kings, queens, emperors, dictators.  All these wars were between kings, queens, emperors, and dictators.\"\n",
      "00:27:15.240,\" Never between two major democracies.  And so I think with the spread of this technology and which would accelerate with the coming of brain net, it means that, well, we will still have wars.  Wars, of course, is politics by other means, but they'll be less intense and less frequent.  Do you have worries of longer term existential risk from technology, from AI? So I think that's a wonderful vision of a future where war is a distant memory, but now there's another agent.\"\n",
      "00:27:53.840,\" There's somebody else that's able to create conflict, that's able to create harm, AI systems.  So do you have worry about such AI systems? Well, yes, that is an existential risk, but again, I think an existential risk, not for this century.\"\n",
      "00:28:09.800,\" I think our grandkids are gonna have to confront this question as robots gradually approach the intelligence of a dog, a cat, and finally that of a monkey.  However, I think we will digitize ourselves as well.  Not only are we gonna merge with our technology, we'll also digitize our personality, our memories, our feelings.\"\n",
      "00:28:30.680,\" You realize during the Middle Ages, there was something called dualism.  Dualism meant that the soul was separate from the body.  When the body died, the soul went to heaven.  That's dualism.  Then in the 20th century, neuroscience came in and said, bah, humbug.\"\n",
      "00:28:47.720,\" Every time we look at the brain, it's just neurons.  That's it, folks, period, end of story.  Bunch of neurons firing.  Now we're going back to dualism.  Now we realize that we can digitize human memories, feelings, sensations, and create a digital copy of ourselves, and that's called the Connectome Project.  Billions of dollars are now being spent to do not just the genome project of sequencing the genes of our body, but the Connectome Project, which is to map the entire connections of the human brain.\"\n",
      "00:29:26.120,\" And even before then, already in Silicon Valley, today, at this very moment, you can contact Silicon Valley companies that are willing to digitize your relatives because some people want to talk to their parents.\"\n",
      "00:29:39.760,\" There are unresolved issues with their parents, and one day, yes, firms will digitize people, and you'll be able to talk to them a reasonable facsimile.  We leave a digital trail.  Our ancestors did not.  Our ancestors were lucky if they had one line, just one line in a church book, saying the date they were baptized and the date they died.\"\n",
      "00:30:04.400,\" That's it.  That was their entire digital memory.  I mean, their entire digital existence summarized in just a few letters of the alphabet, a whole life.  Now we digitize everything.  Every time you sneeze, you digitize it.  You put it on the internet.\"\n",
      "00:30:22.800,\" And so I think that we are gonna digitize ourselves and give us digital immortality.  We'll not only have biologic genetic immortality of some sort, but also digital immortality.  And what are we gonna do with it? I think we should send it into outer space.  If you digitize the human brain and put it on a laser beam and shoot it to the moon, you're on the moon in one second.\"\n",
      "00:30:48.840,\" Shoot it to Mars, you're on Mars in 20 minutes.  Shoot it to Pluto, you're on Pluto in eight hours.  Think about it for a moment.  You can have breakfast in New York and for a morning snack, vacation on the moon, then zap your way to Mars by noontime, journey through the asteroid belt of the afternoon, and then come back for dinner in New York at night.\"\n",
      "00:31:11.960,\" All in a day's work at the speed of light.  Now, this means that you don't need booster rockets.  You don't need weightlessness problems.  You don't need to worry about meteorites.  And what's on the moon? On the moon, there is a mainframe that downloads your laser beam's information.\"\n",
      "00:31:31.080,\" And where does it download the information into? An avatar.  Now, what does that avatar look like? Anything you want.  Think about it for a moment.  You could be Superman, Superwoman, on the moon, on Mars, traveling throughout the universe at the speed of light, downloading your personality into any vehicle you want.\"\n",
      "00:31:55.240,\" Now, let me stick my neck out.  So far, everything I've been saying is well within the laws of physics.  Well within the laws of physics.  Now, let me go outside the laws of physics again.  Here we go.  I think this already exists.  I think outside the Earth, there could be a super highway a laser highway of laser porting with billions of souls of aliens zapping their way across the galaxy.\"\n",
      "00:32:20.880,\" Now, let me ask you a question.  Are we smart enough to determine whether such a thing exists or not? No, this could exist right outside the orbit of the planet Earth.\"```\n",
      "\n",
      "- Capture the main points, themes, and key takeaways of the text.\n",
      "- Ensure to include the most significant arguments, insights, and conclusions drawn from the text.\n",
      "- Ensure to include the timestamp when the spakers started talking about the main point.\n",
      "- Only respond with the timestamp and the concise summary, nothing else. \n",
      "\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text delimited by triple backquotes:\n",
      "\n",
      "```00:32:20.880,\" Now, let me ask you a question.  Are we smart enough to determine whether such a thing exists or not? No, this could exist right outside the orbit of the planet Earth.\"\n",
      "00:32:32.960,\" And we're too stupid in our technology to even prove it or disprove it.  We would need the aliens on this laser super highway to help us out, to send us a human interpretable signal.  I mean, it ultimately boils down to the language of communication, but that's an exciting possibility that actually the sky is filled with aliens.\"\n",
      "00:32:59.080,\" The aliens could already be here.  And we're just so oblivious that we're too stupid to know it.  See, they don't have to be in alien form with little green men.  They can be in any form they want in an avatar of their creation.  Well, in fact, they could very well be.  They can even look like us.\"\n",
      "00:33:17.320,\" Exactly.  We'd never know.  One of us could be an alien.  You know, in the zoo, did you know that we sometimes have zookeepers that imitate animals? We create a fake animal and we put it in so that the animal is not afraid of this fake animal.  And of course, these animals brains, their brain is about as big as a walnut.\"\n",
      "00:33:37.080,\" They accept these dummies as if they were real.  So an alien civilization in outer space would say, oh yeah, human brains are so tiny.  We could put a dummy on their world, an avatar, and they'd never know it.  That would be an entertaining thing to watch from the alien perspective.\"\n",
      "00:33:55.040,\" So you kind of implied that with a digital form of our being, but also biologically, do you think one day technology will allow individual human beings to become immortal besides just through the ability to digitize our essence? Yeah, I think that artificial intelligence will give us the key to genetic immortality.  You see, in the coming decades, everyone's gonna have their gene sequence.\"\n",
      "00:34:21.280,\" We'll have billions of genomes of old people, billions of genomes of young people.  And what are we gonna do with it? We're gonna run it through an AI machine, which has pattern recognition, to look for the age genes.  In other words, the fountain of youth that emperors, kings, and queens lusted over.\"\n",
      "00:34:41.920,\" The fountain of youth will be found by artificial intelligence.  Artificial intelligence will identify where these age genes are located.  First of all, what is aging? We now know what aging is.  Aging is the buildup of errors.  That's all aging is, the buildup of genetic errors.\"\n",
      "00:35:03.560,\" This means that cells eventually become slower, sluggish, they go into senescence, and they die.  In fact, that's why we die.  We die because of the buildup of mistakes in our genome, in our cellular activity.  But you see, in the future, we'll be able to fix those genes with CRISPR type technologies, and perhaps even live forever.\"\n",
      "00:35:27.400,\" So let me ask you a question.  Where does aging take place in a car? Given a car, where does aging take place? Well, it's obvious, the engine, right? A, that's where you have a lot of moving parts.  B, that's where you have combustion.  Well, where in the cell do we have combustion? The mitochondria.\"\n",
      "00:35:48.760,\" We now know where aging takes place.  And if we cure many of the mistakes that build up in the mitochondria of the cell, we could become immortal.  Let me ask you, if you yourself could become immortal, would you? Damn straight.  No, I think about it for a while, because of course, it depends on how you become immortal.\"\n",
      "00:36:14.880,\" You know, there's a famous myth of Tithonus.  It turns out that years ago, in the Greek mythology, there was the saga of Tithonus and Aurora.  Aurora was the goddess of the dawn, and she fell in love with a mortal, a human called Tithonus.  And so Aurora begged Zeus to grant her the gift of immortality to give to her lover.  So Zeus took pity on Aurora and made Tithonus immortal.\"\n",
      "00:36:47.080,\" But you see, Aurora made a mistake, a huge mistake.  She asked for immortality, but she forgot to ask for eternal youth.  So poor Tithonus got older and older and older every year, decrepit, a bag of bones, but he could never die.  Never die.  Quality of life is important.\"\n",
      "00:37:11.600,\" So I think immortality is a great idea, as long as you also have immortal youth as well.  Now, I personally believe, and I cannot prove this, but I personally believe that our grandkids may have the option of reaching the age of 30 and then stopping.  They may like being age 30, because you have wisdom, you have all the benefits of age and maturity, and you still live forever with a healthy body.\"\n",
      "00:37:39.280,\" Our descendants may like being 30 for several centuries.  Is there an aspect of human existence that is meaningful only because we're mortal? Well, every waking moment, we don't think about it this way, but every waking moment, actually, we are aware of our death and our mortality.\"\n",
      "00:38:00.240,\" Think about it for a moment.  When you go to college, you realize that you are in a period of time where soon you will reach middle age and have a career.  And after that, you'll retire and then you'll die.  And so even as a youth, even as a child, without even thinking about it, you are aware of your own death, because it sets limits to your lifespan.\"\n",
      "00:38:24.680,\" I gotta graduate from high school.  I gotta graduate from college.  Why? Because you're gonna die.  Because unless you graduate from high school, unless you graduate from college, you're not gonna enter old age with enough money to retire and then die.\"\n",
      "00:38:39.480,\" And so, yeah, people think about it unconsciously, because it affects every aspect of your being.  The fact that you go to high school, college, get married, have kids, there's a clock, a clock ticking even without your permission.  It gives a sense of urgency.\"\n",
      "00:38:58.160,\" Do you yourself, I mean, there's so much excitement and passion in the way you talk about physics and the way you talk about technology in the future.  Do you yourself meditate on your own mortality? Do you think about this clock that's ticking? Well, I try not to, because it then begins to affect your behavior.\"\n",
      "00:39:19.600,\" You begin to alter your behavior to match your expectation of when you're gonna die.  So let's talk about youth, and then let's talk about death, okay? When I interview scientists on radio, I often ask them, what made the difference? How old were you? What changed your life? And they always say more or less the same thing.\"\n",
      "00:39:44.080,\" No, these are Nobel Prize winners, directors of major laboratories, very distinguished scientists.  They always say, when I was 10, when I was 10, something happened.  It was a visit to the planetarium.  It was a telescope.\"\n",
      "00:39:59.400,\" For Steven Weinberg, winner of the Nobel Prize, it was the chemistry kit.  For Heinz Pagels, it was a visit to the planetarium.  For Isidor Rabi, it was a book about the planets.  For Albert Einstein, it was a compass.  Something happened, which gives them this existential shock.  Because you see, before the age of 10, everything is mommy and daddy, mommy and dad.\"\n",
      "00:40:22.520,\" That's your universe, mommy and daddy.  Around the age of 10, you begin to wonder, what's beyond mommy and daddy? And that's when you have this epiphany, when you realize, oh my God, there's a universe out there, a universe of discovery.  And that sensation stays with you for the rest of your life.\"\n",
      "00:40:45.520,\" You still remember that shock that you felt gazing at the universe.  And then you hit the greatest destroyer of scientists known to science.  The greatest destroyer of scientists known to science is junior high school.  When you hit junior high school, folks, it's all over.  It's all over.\"\n",
      "00:41:10.720,\" Because in junior high school, people say, hey, stupid.  I mean, you like that nerdy stuff.  And your friends shun you.  All of a sudden, people think you're a weirdo.  And scientists made boring.  Richard Feynman, the Nobel Prize winner, when he was a child, his father would take him into the forest.\"\n",
      "00:41:31.520,\" And the father would teach him everything about birds, why they're shaped the way they are, their wings, the coloration, the shape of their beak, everything about birds.  So one day, a bully comes up to the future Nobel Prize winner and says, hey, Dick, what's the name of that bird over there? Well, he didn't know.\"\n",
      "00:41:53.040,\" He knew everything about that bird except its name.  So he said, I don't know.  And then the bully said, what's the matter, Dick? You stupid or something? And then in that instant, he got it.  He got it.  He realized that for most people, science is giving names to birds.\"\n",
      "00:42:15.960,\" That's what science is.  You know lots of names of obscure things.  Hey, people say, you're smart.  You're smart.  You know all the names of the dinosaurs.  You know all the names of the plants.  No, that's not science at all.  Science is about principles, concepts, physical pictures.\"\n",
      "00:42:36.440,\" That's what science is all about.  My favorite quote from Einstein is that, unless you can explain the theory to a child, the theory is probably worthless.  Meaning that all great theories are not big words.  All great theories are simple concepts, principles, basic physical pictures.  Relativity is all about clocks, meter sticks, rocket ships and locomotives.\"\n",
      "00:43:07.160,\" Newton's laws of gravity are all about balls and spinning wheels and things like that.  That's what physics and science is all about, not memorizing things.  And that stays with you for the rest of your life.  So even in old age, I've noticed that these scientists, when they sit back, they still remember.\"```\n",
      "\n",
      "- Capture the main points, themes, and key takeaways of the text.\n",
      "- Ensure to include the most significant arguments, insights, and conclusions drawn from the text.\n",
      "- Ensure to include the timestamp when the spakers started talking about the main point.\n",
      "- Only respond with the timestamp and the concise summary, nothing else. \n",
      "\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text delimited by triple backquotes:\n",
      "\n",
      "```00:43:07.160,\" Newton's laws of gravity are all about balls and spinning wheels and things like that.  That's what physics and science is all about, not memorizing things.  And that stays with you for the rest of your life.  So even in old age, I've noticed that these scientists, when they sit back, they still remember.\"\n",
      "00:43:28.000,\" They still remember that flush, that flush of excitement they felt with that first telescope, that first moment when they encountered the universe.  That keeps them going.  By the way, I should point out that when I was eight, something happened to me as well.  When I was eight years old, it was in all the papers that a great scientist had just died.\"\n",
      "00:43:56.720,\" And they put a picture of his desk on the front page.  That's it, just a simple picture of the front page of the newspapers of his desk.  That desk had a book on it, which was opened.  And the caption said more or less, this is the unfinished manuscript from the greatest scientists of our time.\"\n",
      "00:44:17.520,\" So I said to myself, well, why couldn't he finish it? What's so hard that you can't finish it if you're a great scientist? It's a homework problem, right? You go home, you solve it, or you ask your mom, why couldn't he solve it? So to me, this was a murder mystery.  This was greater than any adventure story.\"\n",
      "00:44:37.800,\" I had to know why the greatest scientists of our time couldn't finish something.  And then over the years, I found out the guy had a name, Albert Einstein, and that book was The Theory of Everything.  It was unfinished.  Well, today I can read that book.  I can see all the dead ends and false starts that he made.  And I began to realize that he lost his way because he didn't have a physical picture to guide him on the third try.\"\n",
      "00:45:09.400,\" On the first try, he talked about clocks and lightning bolts and meter sticks, and that gave us special relativity, which gave us the atomic bomb.  The second great picture was gravity with balls rolling on curved surfaces.\"\n",
      "00:45:26.320,\" And that gave us the Big Bang, creation of the universe, black holes.  On the third try, he missed it.  He had no picture at all to guide him.  In fact, there's a quote I have where he said, I'm still looking.  I'm still looking for that picture.  He never found it.\"\n",
      "00:45:45.800,\" Well, today we think that picture is strength theory.  The strength theory can unify gravity and this mysterious thing that Einstein didn't like, which is quantum mechanics, or couldn't quite pin down and make sense of.  That's right.  Mother nature has two hands, a left hand and a right hand.  The left hand is a theory of the small.\"\n",
      "00:46:05.200,\" The right hand is a theory of the big.  The theory of the small is the quantum theory, the theory of atoms and quarks.  The theory of the big is relativity, the theory of black holes, big bangs.  The problem is the left hand does not talk to the right hand.  They hate each other.  The left hand is based on discrete particles.\"\n",
      "00:46:27.400,\" The right hand is based on smooth surfaces.  How do you put these two things together into a single theory? They hate each other.  The greatest minds of our time, the greatest minds of our time worked on this problem and failed.  Today, the only theory that has survived every challenge so far is string theory.\"\n",
      "00:46:49.520,\" That doesn't mean string theory is correct.  It could very well be wrong, but right now it's the only game in town.  Some people come up to me and say, ''Professor, I don't believe in string theory.  Give me an alternative.'' And I tell them there is none.\"\n",
      "00:47:05.760,\" Get used to it.  It's the best theory we got.  It's the only theory we have.  Do you see, you know, the strings kind of inspire a view, as did atoms and particles and quarks, but especially strings inspire a view of a universe as a kind of information processing system, as a computer of sorts.\"\n",
      "00:47:31.560,\" Do you see the universe in this way? No.  Some people think, in fact, the whole universe is a computer of some sort.  And they believe that perhaps everything, therefore, is a simulation.\"\n",
      "00:47:44.040,\" Yes.  I don't think so.  I don't think that there is a super video game where we are nothing but puppets dancing on the screen and somebody hit the play button and here we are talking about simulations.  No.  Even Newtonian mechanics says that the weather, the simple weather is so complicated with trillions upon trillions of atoms that it cannot be simulated in a finite amount of time.\"\n",
      "00:48:10.840,\" In other words, the smallest object which can describe the weather and simulate the weather is the weather itself.  The smallest object that can simulate a human is the human itself.\"\n",
      "00:48:26.960,\" And if you had quantum mechanics, it becomes almost impossible to simulate it with a conventional computer.  This quantum mechanics deals with all possible universes, parallel universes, a multiverse of universes.  And so the calculation just spirals out of control.  Now, so far, there's only one way where you might be able to argue that the universe is a simulation.\"\n",
      "00:48:54.160,\" And this is still being debated by quantum physicists.  It turns out that if you throw the encyclopedia into a black hole, the information is not lost.  Eventually it winds up on the surface of the black hole.  Now, the surface of the black hole is finite.  In fact, you can calculate the maximum amount of information you can store in a black hole.\"\n",
      "00:49:15.640,\" It's a finite number.  It's a calculable number, believe it or not.  Now, if the universe were made out of black holes, which is the maximum universe you can conceive of, each universe, each black hole has a finite amount of information.  Therefore, ergo, da da! Ergo, the total amount of information in a universe is finite.\"\n",
      "00:49:38.880,\" This is mind boggling.  This, I consider mind boggling, that all possible universes are countable and all possible universes can be summarized in a number, a number you can write on a sheet of paper, all possible universes, and it's a finite number.\"\n",
      "00:49:55.160,\" Now, it's huge.  It's a number beyond human imagination.  It's a number based on what is called a Planck length, but it's a number.  And so if a computer could ever simulate that number, then the universe would be a simulation.  So theoretically, because the amount of information is finite, well, there necessarily must be able to exist a computer.\"\n",
      "00:50:19.880,\" It's just, from an engineering perspective, maybe impossible to build.  Yes, no computer can build a universe capable of simulating the entire universe, except the universe itself.  So that's your intuition, that our universe is very efficient, and so there's no shortcuts.\"\n",
      "00:50:37.960,\" Right, two reasons why I believe the universe is not a simulation.  First, the calculational numbers are just incredible.  No finite Turing machine can simulate the universe.  And second, why would any super intelligent being simulate humans? If you think about it, most humans are kind of stupid.  I mean, we do all sorts of crazy, stupid things, right? And we call it art, we call it humor.\"\n",
      "00:51:03.880,\" We call it human civilization.  So why should an advanced civilization go through all that effort just to simulate Saturday Night Live? Well, that's a funny idea, but it's also, do you think it's possible that the act of creation cannot anticipate humans? You simply set the initial conditions and set a bunch of physical laws, and just for the fun of it, see what happens.\"\n",
      "00:51:28.760,\" You launch the thing, so you're not necessarily simulating everything.  You're not simulating every little bit in the sense that you could predict what's going to happen, but you set the initial conditions, set the laws, and see what kind of fun stuff happens.\"\n",
      "00:51:43.200,\" Well, in some sense, that's how life got started.  In the 1950s, Stanley did what is called the Miller experiment.  He put a bunch of hydrogen gas, methane, toxic gases with liquid and a spark in a small glass beaker.  And then he just walked away for a few weeks, came back a few weeks later, and bingo.\"\n",
      "00:52:08.480,\" Out of nothing and chaos came amino acids.  If he had left it there for a few years, he might have gotten protein, protein molecules for free.  That's probably how life got started, as a accident.  And if he had left it there for perhaps a few million years, DNA might have formed in that beaker.  And so we think that, yeah, DNA, life, all that could have been an accident if you wait long enough.\"\n",
      "00:52:38.480,\" And remember, our universe is roughly 13.8 billion years old.  That's plenty of time for lots of random things to happen, including life itself.  Yeah, we could be just a beautiful little random moment.  And there could be an infinite number of those throughout the history of the universe, many creatures like us.  We perhaps are not the epitome of what the universe is created for.\"\n",
      "00:53:07.960,\" Thank God.  Let's hope not.  Just look around.  Yeah.  Look to your left, look to your right.  When do you think the first human will step foot on Mars? I think it's a good chance in the 2030s that we will be on Mars.\"\n",
      "00:53:25.280,\" In fact, there's no physics reason why we can't do it.  It's an engineering problem.  It's a very difficult and dangerous engineering problem, but it is an engineering problem.  And in my book, Future of Humanity, I even speculate beyond that, that by the end of this century, we'll probably have the first starships.\"\n",
      "00:53:45.720,\" The first starships will not look like the Enterprise at all.  They'll probably be small computer chips that are fired by laser beams with parachutes.  And like what Stephen Hawking advocated, the Breakthrough Starshot program could send ships to the nearby stars, traveling at 20% the speed of light, reaching Alpha Centauri in about 20 years time.\"```\n",
      "\n",
      "- Capture the main points, themes, and key takeaways of the text.\n",
      "- Ensure to include the most significant arguments, insights, and conclusions drawn from the text.\n",
      "- Ensure to include the timestamp when the spakers started talking about the main point.\n",
      "- Only respond with the timestamp and the concise summary, nothing else. \n",
      "\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text delimited by triple backquotes:\n",
      "\n",
      "```00:53:45.720,\" The first starships will not look like the Enterprise at all.  They'll probably be small computer chips that are fired by laser beams with parachutes.  And like what Stephen Hawking advocated, the Breakthrough Starshot program could send ships to the nearby stars, traveling at 20% the speed of light, reaching Alpha Centauri in about 20 years time.\"\n",
      "00:54:09.080,\" Beyond that, we should have fusion power.  Fusion power is, in some sense, one of the ultimate sources of energy, but it's unstable.  And we don't have fusion power today.  Now, why is that? First of all, stars form almost for free.  You get a bunch of gas large enough, it becomes a star.\"\n",
      "00:54:29.560,\" I mean, you don't even have to do anything to it, and it becomes a star.  Why is fusion so difficult to put on the Earth? Because in outer space, stars are monopoles.  They are pole, single poles that are spherically symmetric.  And it's very easy to get spherically symmetric configurations of gas to compress into a star.  It just happens naturally all by itself.\"\n",
      "00:54:53.800,\" The problem is magnetism is bipolar.  You have a North Pole and a South Pole.  And it's like trying to squeeze a long balloon.  Take a long balloon and try to squeeze it.  You squeeze one side, it bulges out the other side.  Well, that's the problem with fusion machines.  We use magnetism with a North Pole and a South Pole to squeeze gas, and all sorts of anomalies and horrible configurations can take place because we're not squeezing something uniformly like in a star.\"\n",
      "00:55:24.920,\" Stars, in some sense, are for free.  Fusion on the Earth is very difficult.  But I think it's inevitable.  And it'll eventually give us unlimited power from seawater.  So seawater will be the ultimate source of energy for the planet Earth.\"\n",
      "00:55:41.160,\" Why? What's the intuition there? Because we'll extract hydrogen from seawater, burn hydrogen in a fusion reactor to give us unlimited energy without the meltdown, without the nuclear waste.  Why do we have meltdowns? We have meltdowns because in the fusion reactors, every time you split the uranium atom, you get nuclear waste.\"\n",
      "00:56:00.760,\" Tons of it.  30 tons of nuclear waste per reactor per year.  And it's hot.  It's hot for thousands, millions of years.  That's why we have meltdowns.  But you see, the waste product of a fusion reactor is helium gas.\"\n",
      "00:56:17.480,\" Helium gas is actually commercially valuable.  You can make money selling helium gas.  And so the waste product of a fusion reactor is helium, not nuclear waste that we find in a commercial fission plant.  And that controlling, mastering and controlling fusion allows us to, converts us into a type one, I guess, civilization, right? Yeah, probably the backbone of a type one civilization will be fusion power.\"\n",
      "00:56:45.720,\" We, by the way, are type zero.  We don't even rate on this scale.  We get our energy from dead plants, for God's sake, oil and coal.  But we are about 100 years from being type one.\"\n",
      "00:56:56.320,\" Get a calculator.  In fact, Carl Sagan calculated that we are about 0.7, fairly close to a 1.0.  For example, what is the internet? The internet is the beginning of the first type one technology to enter into our century.  The first planetary technology is the internet.  What is the language of type one? On the internet already, English and Mandarin Chinese are the most dominant languages on the internet.\"\n",
      "00:57:26.880,\" And what about the culture? We're seeing a type one sports, soccer, the Olympics, a type one music, youth culture, rock and roll, rap music, type one fashion, Gucci, Chanel, a type one economy, the European Union, NAFTA, what have you.  So we're beginning to see the beginnings of a type one culture in a type one civilization.\"\n",
      "00:57:52.200,\" And inevitably, it will spread beyond this planet.  So you talked about sending at 20% the speed of light on a chip into Alpha Centauri.  But in a slightly nearer term, what do you think about the idea when we still have to send our biological bodies the colonization of planets, colonization of Mars? Do you see us becoming a two planet species ever or anytime soon? Well, just remember the dinosaurs did not have a space program.\"\n",
      "00:58:28.760,\" And that's why they're not here today.  How come there are no dinosaurs in this room today? Because they didn't have a space program.  We do have a space program, which means that we have an insurance policy.\"\n",
      "00:58:40.760,\" Now, I don't think we should bankrupt the Earth or deplete the Earth to go to Mars.  That's too expensive and not practical.  But we need a settlement, a settlement on Mars in case something bad happens to the planet Earth.  And that means we have to terraform Mars.  Now, to terraform Mars, if we could raise the temperature of Mars by six degrees, six degrees, then the polar ice caps begin to melt, releasing water vapor.\"\n",
      "00:59:08.480,\" Water vapor is a greenhouse gas.  It causes even more melting of the ice caps.  So it becomes a self fulfilling prophecy.  It feeds on itself.  It becomes autocatalytic.  And so once you hit six degrees, rising of the temperature on Mars by six degrees, it takes off.\"\n",
      "00:59:27.200,\" And we melt the polar ice caps.  And liquid water once again flows in the rivers, the canals, the channels, and the oceans of Mars.  Mars once had an ocean, we think, about the size of the United States.  And so that is a possibility.\"\n",
      "00:59:44.320,\" Now, how do we get there? How do we raise the temperature of Mars by six degrees? Elon Musk would like to detonate hydrogen warheads on the polar ice caps.  Well, I'm not sure about that.  Because we don't know that much about the effects of detonating hydrogen warheads to melt the polar ice caps.  And who wants to glow in the dark at night reading the newspaper? So I think there are other ways to do it with solar satellites.\"\n",
      "01:00:12.000,\" You can have satellites orbiting Mars that beam sunlight onto the polar ice caps, melting the polar ice caps.  Mars has plenty of water.  It's just frozen.  I think you paint an inspiring and a wonderful picture of the future.\"\n",
      "01:00:29.760,\" I think you've inspired and educated thousands, if not millions.  Michio, it's been an honor.  Thank you so much for talking today.  My pleasure.\"```\n",
      "\n",
      "- Capture the main points, themes, and key takeaways of the text.\n",
      "- Ensure to include the most significant arguments, insights, and conclusions drawn from the text.\n",
      "- Ensure to include the timestamp when the spakers started talking about the main point.\n",
      "- Only respond with the timestamp and the concise summary, nothing else. \n",
      "\n",
      "CONCISE SUMMARY:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Write a concise summary of the following text delimited by triple backquotes.\n",
      "\n",
      "Return your response in bullet points which covers the key points of the text and     the timestamp when the spakers started talking about the main point. \n",
      "```00:01:09.920 - Michio Kaku believes that contact with aliens or at least hearing from them is possible within this century due to the large number of potential Earth-sized planets in the Milky Way galaxy and the existence of billions of galaxies in the visible universe.\n",
      "\n",
      "00:03:02.660 - Michio Kaku explains that if we make contact with aliens, we need to understand their level of sophistication and determine where they are on the Kardashev scale, which ranks civilizations based on their energy and information capabilities.\n",
      "\n",
      "00:05:39.760 - Michio Kaku discusses the possibility of type four and type five civilizations on the Kardashev scale, which would be capable of harnessing dark energy and accessing energy sources outside of our universe, respectively.\n",
      "\n",
      "00:06:42.120 - Michio Kaku explains the concept of the multiverse, where multiple universes are constantly being created, and how it can reconcile the ideas of creation in Buddhism and Christianity.\n",
      "\n",
      "00:09:41.680 - Michio Kaku mentions that string theory, his area of expertise, is a multiverse theory that suggests all particles are vibrations on tiny strings, and the universe is a symphony of these strings.\n",
      "\n",
      "00:10:28.280 - Physics is the harmonies you can write on vibrating strings, chemistry is the melodies you can play on these strings, and the universe is a symphony of strings.\n",
      "00:11:35.600 - Einstein believed in the God of order, simplicity, harmony, and beauty, not the personal God of the Bible.\n",
      "00:12:38.640 - The universe is like a library with mysterious and magical things yet to be discovered.\n",
      "00:13:32.320 - Science is about natural law, and religion is about ethics and how to be a good person.\n",
      "00:14:28.040 - Our sense of right and wrong is outside the reach of physics and string theory.\n",
      "00:15:22.880 - Alien civilizations are likely to ignore us rather than befriend or destroy us.\n",
      "00:16:39.360 - Alien civilizations probably won't find value in gold or human art and literature.\n",
      "00:17:56.160 - Intelligent beings typically have stereo eyesight, an opposable thumb or tentacle, and language.\n",
      "00:19:16.640 - Humans are the only animals with all three criteria for intelligence.\n",
      "00:20:01.040 - Aliens from outer space are likely to have descended from predators and have ways to manipulate the environment and communicate knowledge.\n",
      "00:21:35.480 - In the future, robots may become dangerous and require fail-safe measures, but eventually, humans may merge with them.\n",
      "\n",
      "00:21:35.480 - In the future, robots may become smart enough to remove their fail-safe chips and merge with humans.\n",
      "00:22:29.000 - Brain-machine interfaces, such as Neuralink, have promising potential in the near term.\n",
      "00:23:07.760 - Memory chips could be developed to help Alzheimer's patients regain their memories.\n",
      "00:23:33.200 - The future of the internet could involve telepathic communication and sharing emotions and sensations.\n",
      "00:24:34.680 - Brain net could replace traditional entertainment, allowing for the transmission of emotions and memories.\n",
      "00:24:55.880 - Brain net could deepen personal relationships and empathy towards others.\n",
      "00:26:15.960 - Technology, including the internet, has a moral direction and can spread knowledge and empower people.\n",
      "00:27:53.840 - AI systems pose an existential risk, but it is not a concern for this century.\n",
      "00:28:30.680 - The Connectome Project aims to digitize human memories and create digital copies of ourselves.\n",
      "00:29:26.120 - Silicon Valley companies already offer services to digitize and communicate with deceased relatives.\n",
      "00:30:22.800 - Digitizing ourselves could lead to digital immortality and the ability to explore space through laser beams.\n",
      "00:31:55.240 - The possibility of a laser highway outside Earth where aliens travel cannot be determined with our current knowledge.\n",
      "\n",
      "00:32:20.880 - The possibility of the existence of aliens outside the orbit of Earth and our inability to prove or disprove it.\n",
      "00:32:59.080 - Speculation that aliens could already be on Earth in various forms, including looking like humans.\n",
      "00:33:55.040 - The potential for technology, particularly artificial intelligence, to allow humans to become genetically immortal.\n",
      "00:34:41.920 - Aging is caused by the buildup of genetic errors, and future technologies like CRISPR could potentially fix these errors and extend human lifespan.\n",
      "00:35:48.760 - Aging takes place in the mitochondria of cells, and addressing the mistakes in the mitochondria could lead to immortality.\n",
      "00:36:14.880 - The importance of eternal youth along with immortality, as illustrated by the myth of Tithonus.\n",
      "00:37:39.280 - The possibility of future generations choosing to remain at the age of 30 for centuries, combining wisdom and youth.\n",
      "00:38:00.240 - The awareness of mortality and its impact on decision-making and the sense of urgency in life.\n",
      "00:39:19.600 - The avoidance of meditating on mortality to prevent it from influencing behavior.\n",
      "00:39:44.080 - The transformative experiences in childhood that lead individuals to pursue scientific careers.\n",
      "00:41:10.720 - The negative impact of junior high school on scientific interests and the perception of scientists.\n",
      "00:42:36.440 - The essence of science being about principles, concepts, and physical pictures rather than memorization.\n",
      "00:43:07.160 - The importance of simplicity and the ability to explain scientific theories to children.\n",
      "\n",
      "00:43:07.160 - The main point is that physics and science are not about memorizing things, but about understanding concepts that stay with you for life.\n",
      "00:43:28.000 - Scientists remember the excitement they felt when they first encountered the universe, which keeps them motivated.\n",
      "00:44:17.520 - The speaker became intrigued by Albert Einstein's unfinished manuscript and realized that he lost his way because he lacked a physical picture to guide him.\n",
      "00:45:09.400 - The speaker explains the theories of special relativity and gravity, and how string theory could potentially unify gravity and quantum mechanics.\n",
      "00:46:49.520 - String theory is currently the only theory that has survived every challenge, but it may not be correct.\n",
      "00:47:44.040 - The idea that the universe is a simulation is debated, but the speaker believes it is unlikely due to the complexity of simulating the universe.\n",
      "00:49:38.880 - The speaker explains that the finite amount of information in the universe suggests the possibility of a computer simulating it, but building such a computer may be impossible.\n",
      "00:50:37.960 - The speaker argues against the idea of the universe being a simulation, citing the incredible calculations required and the unlikelihood of simulating humans.\n",
      "00:51:28.760 - The speaker suggests that life may have started as an accident, and that the universe allows for random events to occur over time.\n",
      "00:53:25.280 - The speaker believes that humans could step foot on Mars in the 2030s and that by the end of the century, starships could be possible through programs like Breakthrough Starshot.\n",
      "\n",
      "00:53:45.720 - The Breakthrough Starshot program aims to send small computer chips to nearby stars at 20% the speed of light, reaching Alpha Centauri in about 20 years.\n",
      "\n",
      "00:54:09.080 - Fusion power is an ultimate source of energy, but it is difficult to achieve on Earth due to the bipolar nature of magnetism. However, mastering fusion could provide unlimited power from seawater.\n",
      "\n",
      "00:55:41.160 - Fusion reactors produce helium gas as waste, which is commercially valuable, unlike the nuclear waste produced by fission reactors. Fusion power could lead to a type one civilization.\n",
      "\n",
      "00:56:56.320 - Humanity is close to becoming a type one civilization, with the internet being the first type one technology. Type one culture, economy, and sports are already emerging.\n",
      "\n",
      "00:57:52.200 - Eventually, the type one civilization will expand beyond Earth, making colonization of other planets necessary as an insurance policy for the survival of the human species.\n",
      "\n",
      "00:58:40.760 - Terraforming Mars by raising its temperature by six degrees could melt the polar ice caps and release water vapor, potentially leading to liquid water and the possibility of a settlement on Mars.\n",
      "\n",
      "01:00:12.000 - Instead of detonating hydrogen warheads, solar satellites could be used to beam sunlight onto the polar ice caps of Mars to melt them and release the frozen water.```\n",
      "BULLET POINT SUMMARY:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "episode_summary = summary_chain.run(splitted_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "- Michio Kaku believes contact with aliens is possible within this century due to the large number of potential Earth-sized planets in the Milky Way galaxy and the existence of billions of galaxies in the visible universe. (00:01:09.920)\n",
       "- Understanding the level of sophistication of aliens and their place on the Kardashev scale is important if contact is made. (00:03:02.660)\n",
       "- Type four and type five civilizations on the Kardashev scale could harness dark energy and access energy sources outside of our universe. (00:05:39.760)\n",
       "- The concept of the multiverse can reconcile ideas of creation in Buddhism and Christianity. (00:06:42.120)\n",
       "- String theory suggests all particles are vibrations on tiny strings and the universe is a symphony of these strings. (00:09:41.680)\n",
       "- Alien civilizations are likely to ignore us rather than befriend or destroy us. (00:15:22.880)\n",
       "- Humans are the only animals with stereo eyesight, an opposable thumb or tentacle, and language. (00:19:16.640)\n",
       "- In the future, robots may become dangerous and require fail-safe measures, but eventually, humans may merge with them. (00:21:35.480)\n",
       "- Brain-machine interfaces have promising potential in the near term, including memory chips for Alzheimer's patients. (00:22:29.000)\n",
       "- The future of the internet could involve telepathic communication and sharing emotions and sensations. (00:23:33.200)\n",
       "- Digitizing human memories could lead to digital immortality and the ability to explore space through laser beams. (00:30:22.800)\n",
       "- The possibility of aliens existing outside the orbit of Earth and our inability to prove or disprove it. (00:32:20.880)\n",
       "- Future technologies like CRISPR could potentially fix genetic errors and extend human lifespan. (00:34:41.920)\n",
       "- The importance of eternal youth and immortality, as illustrated by the myth of Tithonus. (00:36:14.880)\n",
       "- The possibility of future generations choosing to remain at the age of 30 for centuries. (00:37:39.280)\n",
       "- The transformative experiences in childhood that lead individuals to pursue scientific careers. (00:39:44.080)\n",
       "- The essence of science being about principles, concepts, and physical pictures rather than memorization. (00:42:36.440)\n",
       "- String theory is currently the only theory that has survived every challenge, but it may not be correct. (00:46:49.520)\n",
       "- The idea that the universe is a simulation is debated, but the speaker believes it is unlikely. (00:47:44.040)\n",
       "- The speaker suggests that life may have started as an accident and that the universe allows for random events to occur over time. (00:51:28.760)\n",
       "- Humans could step foot on Mars in the 2030s and starships could be possible by the end of the century. (00:53:25.280)\n",
       "- Fusion power could provide unlimited energy from seawater and lead to a type one civilization. (00:54:09.080)\n",
       "- Humanity is close to becoming a type one civilization, with the internet being the first type one technology. (00:56:56.320)\n",
       "- Colonization of other planets is necessary for the survival of the human species. (00:57:52.200)\n",
       "- Terraforming Mars by raising its temperature could potentially lead to liquid water and a settlement on Mars. (00:58:40.760)\n",
       "- Solar satellites could be used to melt the polar ice caps of Mars and release water vapor. (01:00:12.000)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(episode_summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling\n",
    "\n",
    "---\n",
    "* Check out [Topic Modeling with Language Models tutorial](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Topic%20Modeling%20With%20Language%20Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structured Data - Turn your LLM output into structured data \n",
    "The LLM just returned a wall of text to us, I want to convert this into structured data I can more easily use elsewhere.\n",
    "\n",
    "We might have been able to do add structured output instructions to the pull above but I preferred to do it in two steps for clarity. Plus the cost us super low so we only have latency to worry about, but that isn't a priority for this tutorial.\n",
    "\n",
    "We will use OpenAI's [function calling](https://youtu.be/0-zlUy7VUjg) to extract each topic.\n",
    "\n",
    "> NOTE: You can use `StructuredOutputParser` also to get the desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema defines the properties you want to find and the expected types and description for those properties. \n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        # Summary of the text\n",
    "        \"summary\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"The concise summary of the text\"\n",
    "        },\n",
    "        # Timestamp\n",
    "        \"timestamp\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\" : \"Timestamp when the spakers started talking about the topic\"\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"summary\", \"timestamp\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_extraction_chain\n",
    "\n",
    "# Using gpt3.5 here because this is an easy extraction task and no need to jump to gpt4\n",
    "extraction_chain = create_extraction_chain(schema, llm)\n",
    "# use extractor for book identification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_structured = extraction_chain.run(episode_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary': 'Michio Kaku believes contact with aliens is possible within this century due to the large number of potential Earth-sized planets in the Milky Way galaxy and the existence of billions of galaxies in the visible universe.',\n",
       "  'timestamp': '00:01:09.920'},\n",
       " {'summary': 'Understanding the level of sophistication of aliens and their place on the Kardashev scale is important if contact is made.',\n",
       "  'timestamp': '00:03:02.660'},\n",
       " {'summary': 'Type four and type five civilizations on the Kardashev scale could harness dark energy and tap into the multiverse.',\n",
       "  'timestamp': '00:05:39.760'},\n",
       " {'summary': 'The multiverse theory combines ideas from Buddhism and Christianity and relates to string theory.',\n",
       "  'timestamp': '00:08:11.240'},\n",
       " {'summary': 'Physics is harmonies on vibrating strings, chemistry is melodies on these strings, and the universe is a symphony of strings.',\n",
       "  'timestamp': '00:10:28.280'},\n",
       " {'summary': 'Alien civilizations are likely to ignore us rather than befriend or destroy us.',\n",
       "  'timestamp': '00:15:22.880'},\n",
       " {'summary': 'Humans are the only animals with stereo eyesight, an opposable thumb or tentacle, and language.',\n",
       "  'timestamp': '00:17:56.160'},\n",
       " {'summary': 'In the future, robots may become dangerous and require fail-safe measures, but eventually, humans may merge with them.',\n",
       "  'timestamp': '00:21:35.480'},\n",
       " {'summary': 'Brain-machine interfaces like Neuralink have promising potential.',\n",
       "  'timestamp': '00:22:29.000'},\n",
       " {'summary': 'Digitizing human memories and creating digital copies of ourselves could lead to digital immortality.',\n",
       "  'timestamp': '00:28:30.680'},\n",
       " {'summary': 'Aging is caused by genetic errors, and future technologies like CRISPR could potentially fix these errors and extend human lifespan.',\n",
       "  'timestamp': '00:34:41.920'},\n",
       " {'summary': 'The possibility of future generations choosing to remain at the age of 30 for centuries.',\n",
       "  'timestamp': '00:37:39.280'},\n",
       " {'summary': 'Science is about understanding concepts that stay with you for life, not memorization.',\n",
       "  'timestamp': '00:43:07.160'},\n",
       " {'summary': 'The speaker believes that humans could step foot on Mars in the 2030s and that by the end of the century, starships could be possible through programs like Breakthrough Starshot.',\n",
       "  'timestamp': '00:53:25.280'},\n",
       " {'summary': 'Fusion power could provide unlimited energy from seawater and lead to a type one civilization.',\n",
       "  'timestamp': '00:55:41.160'},\n",
       " {'summary': 'Humanity is close to becoming a type one civilization, with type one culture, sports, music, fashion, and economy already emerging.',\n",
       "  'timestamp': '00:56:56.320'},\n",
       " {'summary': 'The colonization of Mars could serve as a settlement and insurance policy for the survival of humanity.',\n",
       "  'timestamp': '00:57:52.200'},\n",
       " {'summary': 'Alternative methods, such as using solar satellites, could be considered for raising the temperature of Mars instead of detonating hydrogen warheads.',\n",
       "  'timestamp': '01:00:12.000'}]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat Prompt templates for dynamic values\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "\n",
    "system_template = \"\"\"\n",
    "You are a helpful assistant that helps retrieve topics talked about in a short text\n",
    "- You will be given a text\n",
    "- Your goal is to find the topic talked about in the text \n",
    "- Only respond with the topic in 2 or 3 words, nothing else\n",
    "\"\"\"\n",
    "system_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "human_template=\"Text: {text}\" # Simply just pass the text as a human message\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "messages = [\n",
    "    system_prompt,\n",
    "    human_message_prompt,\n",
    "]\n",
    "topic_prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], output_parser=None, partial_variables={}, template='\\nYou are a helpful assistant that helps retrieve topics talked about in a short text\\n- You will be given a text\\n- Your goal is to find the topic talked about in the text \\n- Only respond with the topic in 2 or 3 words, nothing else\\n', template_format='f-string', validate_template=True), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], output_parser=None, partial_variables={}, template='Text: {text}', template_format='f-string', validate_template=True), additional_kwargs={})])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "topic_chain = LLMChain(llm=llm, \n",
    "                       prompt=topic_prompt, \n",
    "                       verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Holder for our topic timestamps\n",
    "timestamp_topic_dict = {}\n",
    "\n",
    "for element in summary_structured:\n",
    "    \n",
    "\n",
    "    text = f\"{element['summary']}\"\n",
    "    topic = topic_chain.run(text)\n",
    "    \n",
    "    timestamp_topic_dict[element['timestamp']] = topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00:01:09.920': 'Alien contact',\n",
       " '00:03:02.660': 'Alien sophistication',\n",
       " '00:05:39.760': 'Kardashev scale',\n",
       " '00:08:11.240': 'Multiverse theory',\n",
       " '00:10:28.280': 'Physics and Chemistry',\n",
       " '00:15:22.880': 'Alien civilizations',\n",
       " '00:17:56.160': 'Humans, animals, characteristics',\n",
       " '00:20:53.680': 'Robots, intelligence, danger',\n",
       " '00:21:35.480': 'Humans merging with robots',\n",
       " '00:22:29.000': 'Brain-machine interfaces',\n",
       " '00:23:33.200': 'Future internet',\n",
       " '00:30:22.800': 'Digital immortality',\n",
       " '00:31:55.240': 'laser highway',\n",
       " '00:33:55.040': 'Aging, mitochondria, immortality',\n",
       " '00:36:14.880': 'Immortality, eternal youth',\n",
       " '00:39:19.600': 'Fear of death',\n",
       " '00:42:36.440': 'Science education',\n",
       " '00:46:49.520': 'String theory',\n",
       " '00:47:44.040': 'universe simulation',\n",
       " '00:53:25.280': 'Mars exploration',\n",
       " '00:55:41.160': 'Fusion power',\n",
       " '00:56:56.320': 'Technology, culture, economy',\n",
       " '00:57:52.200': 'Colonization, survival, planets',\n",
       " '00:58:40.760': 'Terraforming Mars',\n",
       " '01:00:12.000': 'Mars water'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_topic_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ideas\n",
    "\n",
    "* Go to the mentions of the topics\n",
    "* The app ask me questions about the text (for language learning) and create a discussion\n",
    "* Click on named-entity, book in order to play at timestamp\n",
    "* Webapp or Mobile app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
